{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d516db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:46:26.681565Z",
     "iopub.status.busy": "2022-07-22T07:46:26.680496Z",
     "iopub.status.idle": "2022-07-22T07:47:55.266667Z",
     "shell.execute_reply": "2022-07-22T07:47:55.265555Z"
    },
    "papermill": {
     "duration": 88.596658,
     "end_time": "2022-07-22T07:47:55.269239",
     "exception": false,
     "start_time": "2022-07-22T07:46:26.672581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.1\r\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.3/394.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\r\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\r\n",
      "Collecting absl-py~=0.10\r\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting numpy~=1.19.2\r\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\r\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\r\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.1)\r\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\r\n",
      "Collecting grpcio~=1.32.0\r\n",
      "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.19.4)\r\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\r\n",
      "Collecting h5py~=2.10.0\r\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\r\n",
      "Collecting gast==0.3.3\r\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\r\n",
      "Collecting typing-extensions~=3.7.4\r\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\r\n",
      "Collecting six~=1.15.0\r\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.1.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.27.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (59.8.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.12.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.6.15)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.12)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\r\n",
      "Building wheels for collected packages: wrapt\r\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=77037 sha256=72098e49e3868de637575dee9b7345c00ccf0fcb0486507815990a3e4db040d3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\r\n",
      "Successfully built wrapt\r\n",
      "Installing collected packages: wrapt, typing-extensions, tensorflow-estimator, six, numpy, gast, h5py, grpcio, absl-py, tensorflow\r\n",
      "  Attempting uninstall: wrapt\r\n",
      "    Found existing installation: wrapt 1.14.1\r\n",
      "    Uninstalling wrapt-1.14.1:\r\n",
      "      Successfully uninstalled wrapt-1.14.1\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.1.1\r\n",
      "    Uninstalling typing_extensions-4.1.1:\r\n",
      "      Successfully uninstalled typing_extensions-4.1.1\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\r\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.16.0\r\n",
      "    Uninstalling six-1.16.0:\r\n",
      "      Successfully uninstalled six-1.16.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "    Uninstalling numpy-1.21.6:\r\n",
      "      Successfully uninstalled numpy-1.21.6\r\n",
      "  Attempting uninstall: gast\r\n",
      "    Found existing installation: gast 0.4.0\r\n",
      "    Uninstalling gast-0.4.0:\r\n",
      "      Successfully uninstalled gast-0.4.0\r\n",
      "  Attempting uninstall: h5py\r\n",
      "    Found existing installation: h5py 3.1.0\r\n",
      "    Uninstalling h5py-3.1.0:\r\n",
      "      Successfully uninstalled h5py-3.1.0\r\n",
      "  Attempting uninstall: grpcio\r\n",
      "    Found existing installation: grpcio 1.43.0\r\n",
      "    Uninstalling grpcio-1.43.0:\r\n",
      "      Successfully uninstalled grpcio-1.43.0\r\n",
      "  Attempting uninstall: absl-py\r\n",
      "    Found existing installation: absl-py 1.0.0\r\n",
      "    Uninstalling absl-py-1.0.0:\r\n",
      "      Successfully uninstalled absl-py-1.0.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.6.4\r\n",
      "    Uninstalling tensorflow-2.6.4:\r\n",
      "      Successfully uninstalled tensorflow-2.6.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "dask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "tfx-bsl 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15.5, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-transform 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "starlette 0.19.1 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "rich 12.4.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pytorch-lightning 1.6.4 requires typing-extensions>=4.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pytools 2022.1.12 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pylint 2.14.4 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.2 which is incompatible.\r\n",
      "optax 0.1.2 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "nnabla 1.29.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "grpcio-status 1.46.3 requires grpcio>=1.46.3, but you have grpcio 1.32.0 which is incompatible.\r\n",
      "google-cloud-pubsub 2.12.1 requires grpcio<2.0dev,>=1.38.1, but you have grpcio 1.32.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-cloud-storage<2.0.0dev,>=1.26.0, but you have google-cloud-storage 2.1.0 which is incompatible.\r\n",
      "flax 0.5.2 requires rich~=11.1, but you have rich 12.4.4 which is incompatible.\r\n",
      "flax 0.5.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.12.0 which is incompatible.\r\n",
      "featuretools 1.10.0 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\r\n",
      "cmdstanpy 1.0.3 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "black 22.3.0 requires typing-extensions>=3.10.0.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "astroid 2.11.6 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "apache-beam 2.39.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "apache-beam 2.39.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\r\n",
      "aioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "aiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.20 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed absl-py-0.15.0 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 six-1.15.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.10.0.2 wrapt-1.12.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb34a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:47:55.329907Z",
     "iopub.status.busy": "2022-07-22T07:47:55.329602Z",
     "iopub.status.idle": "2022-07-22T07:47:57.825681Z",
     "shell.execute_reply": "2022-07-22T07:47:57.824744Z"
    },
    "papermill": {
     "duration": 2.528928,
     "end_time": "2022-07-22T07:47:57.828084",
     "exception": false,
     "start_time": "2022-07-22T07:47:55.299156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 07:47:55.434661: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from typing import List, Tuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff923b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:47:57.889194Z",
     "iopub.status.busy": "2022-07-22T07:47:57.888227Z",
     "iopub.status.idle": "2022-07-22T07:47:57.894958Z",
     "shell.execute_reply": "2022-07-22T07:47:57.893955Z"
    },
    "papermill": {
     "duration": 0.039485,
     "end_time": "2022-07-22T07:47:57.897310",
     "exception": false,
     "start_time": "2022-07-22T07:47:57.857825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "IMGS_DIR = \"../input/landcoverai/images/\"\n",
    "MASKS_DIR = \"../input/landcoverai/masks/\"\n",
    "OUTPUT_DIR = \"/kaggle/working/output/\"\n",
    "\n",
    "TARGET_SIZE = 256\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 20\n",
    "epochs = 15\n",
    "train_percent = 0.6\n",
    "val_percent = 0.2\n",
    "seed = 47\n",
    "\n",
    "# 0 is background, 1 is building, 2 is woodland, 3 is water, 4 is road\n",
    "class_weights = {0: 1/(1-(1.85+72.02+13.15+3.5)/216.27), 1: 1/(1.85/216.27), 2: 1/(72.02/216.27), 3: 1/(13.15/216.27), 4: 1/(3.5/216.27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9281a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:47:57.982460Z",
     "iopub.status.busy": "2022-07-22T07:47:57.982014Z",
     "iopub.status.idle": "2022-07-22T07:50:21.636515Z",
     "shell.execute_reply": "2022-07-22T07:50:21.635534Z"
    },
    "papermill": {
     "duration": 143.707894,
     "end_time": "2022-07-22T07:50:21.638632",
     "exception": false,
     "start_time": "2022-07-22T07:47:57.930738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed M-33-20-D-c-4-2 1/41\n",
      "Processed M-33-20-D-d-3-3 2/41\n",
      "Processed M-33-32-B-b-4-4 3/41\n",
      "Processed M-33-48-A-c-4-4 4/41\n",
      "Processed M-33-7-A-d-2-3 5/41\n",
      "Processed M-33-7-A-d-3-2 6/41\n",
      "Processed M-34-32-B-a-4-3 7/41\n",
      "Processed M-34-32-B-b-1-3 8/41\n",
      "Processed M-34-5-D-d-4-2 9/41\n",
      "Processed M-34-51-C-b-2-1 10/41\n",
      "Processed M-34-51-C-d-4-1 11/41\n",
      "Processed M-34-55-B-b-4-1 12/41\n",
      "Processed M-34-56-A-b-1-4 13/41\n",
      "Processed M-34-6-A-d-2-2 14/41\n",
      "Processed M-34-65-D-a-4-4 15/41\n",
      "Processed M-34-65-D-c-4-2 16/41\n",
      "Processed M-34-65-D-d-4-1 17/41\n",
      "Processed M-34-68-B-a-1-3 18/41\n",
      "Processed M-34-77-B-c-2-3 19/41\n",
      "Processed N-33-104-A-c-1-1 20/41\n",
      "Processed N-33-119-C-c-3-3 21/41\n",
      "Processed N-33-130-A-d-3-3 22/41\n",
      "Processed N-33-130-A-d-4-4 23/41\n",
      "Processed N-33-139-C-d-2-2 24/41\n",
      "Processed N-33-139-C-d-2-4 25/41\n",
      "Processed N-33-139-D-c-1-3 26/41\n",
      "Processed N-33-60-D-c-4-2 27/41\n",
      "Processed N-33-60-D-d-1-2 28/41\n",
      "Processed N-33-96-D-d-1-1 29/41\n",
      "Processed N-34-106-A-b-3-4 30/41\n",
      "Processed N-34-106-A-c-1-3 31/41\n",
      "Processed N-34-140-A-b-3-2 32/41\n",
      "Processed N-34-140-A-b-4-2 33/41\n",
      "Processed N-34-140-A-d-3-4 34/41\n",
      "Processed N-34-140-A-d-4-2 35/41\n",
      "Processed N-34-61-B-a-1-1 36/41\n",
      "Processed N-34-66-C-c-4-3 37/41\n",
      "Processed N-34-77-A-b-1-4 38/41\n",
      "Processed N-34-94-A-b-2-4 39/41\n",
      "Processed N-34-97-C-b-1-2 40/41\n",
      "Processed N-34-97-D-c-2-4 41/41\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "img_paths = glob(os.path.join(IMGS_DIR, \"*.tif\"))\n",
    "mask_paths = glob(os.path.join(MASKS_DIR, \"*.tif\"))\n",
    "\n",
    "img_paths.sort()\n",
    "mask_paths.sort()\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR + \"images/\"):\n",
    "    os.makedirs(OUTPUT_DIR + \"images/\")\n",
    "    os.makedirs(OUTPUT_DIR + \"masks/\")\n",
    "\n",
    "for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n",
    "    img_filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "    img = cv2.imread(img_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n",
    "\n",
    "    k = 0\n",
    "    for y in range(0, img.shape[0], TARGET_SIZE):\n",
    "        for x in range(0, img.shape[1], TARGET_SIZE):\n",
    "            img_tile = img[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n",
    "            mask_tile = mask[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n",
    "\n",
    "            if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n",
    "                out_img_name = \"{}_{}.jpg\".format(img_filename, k)\n",
    "                out_mask_name = \"{}_m_{}.png\".format(mask_filename, k)\n",
    "                \n",
    "                out_img_path = os.path.join(OUTPUT_DIR+\"images/\", out_img_name)\n",
    "                cv2.imwrite(out_img_path, img_tile)\n",
    "                out_mask_path = os.path.join(OUTPUT_DIR+\"masks/\", out_mask_name)\n",
    "                cv2.imwrite(out_mask_path, mask_tile)\n",
    "\n",
    "            k += 1\n",
    "\n",
    "    print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213eba44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:21.703408Z",
     "iopub.status.busy": "2022-07-22T07:50:21.703075Z",
     "iopub.status.idle": "2022-07-22T07:50:21.715718Z",
     "shell.execute_reply": "2022-07-22T07:50:21.714846Z"
    },
    "papermill": {
     "duration": 0.047169,
     "end_time": "2022-07-22T07:50:21.717666",
     "exception": false,
     "start_time": "2022-07-22T07:50:21.670497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    image_paths = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    mask_paths = sorted(glob(os.path.join(path, \"masks/*\")))\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image.set_shape([TARGET_SIZE, TARGET_SIZE, 3])\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # # If we subtract 1 from mask,\n",
    "    # # we ignore background in the one hot encoding \n",
    "    # # as tf.one_hot will convert -1 to [0, 0, 0, 0]\n",
    "    # # and 0 as [1, 0, 0, 0]\n",
    "\n",
    "    # mask = mask - 1 \n",
    "    mask = tf.one_hot(mask, depth=NUM_CLASSES)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
    "    mask = tf.squeeze(mask)\n",
    "    mask.set_shape([TARGET_SIZE, TARGET_SIZE, NUM_CLASSES])\n",
    "    return image, mask\n",
    "\n",
    "def create_dataset(image_paths, mask_paths):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths), seed=seed)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def test_train_val_split(full_dataset, size, train_percent=0.6, val_percent=0.2, batch_size=8):\n",
    "    train_dataset = full_dataset.take(int(train_percent*size))\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    test_dataset = full_dataset.skip(int(train_percent*size))\n",
    "\n",
    "    val_dataset = test_dataset.take(int(val_percent*size))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.skip(int(val_percent*size))\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a069aa63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:21.781829Z",
     "iopub.status.busy": "2022-07-22T07:50:21.781557Z",
     "iopub.status.idle": "2022-07-22T07:50:23.771741Z",
     "shell.execute_reply": "2022-07-22T07:50:23.770795Z"
    },
    "papermill": {
     "duration": 2.024599,
     "end_time": "2022-07-22T07:50:23.774140",
     "exception": false,
     "start_time": "2022-07-22T07:50:21.749541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 07:50:22.257444: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-22 07:50:22.260788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-22 07:50:22.323243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.323952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-07-22 07:50:22.324025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-22 07:50:22.365556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-22 07:50:22.365679: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-22 07:50:22.390939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-22 07:50:22.400230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-22 07:50:22.429625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-22 07:50:22.449190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-22 07:50:22.453102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-22 07:50:22.453268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.454036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.454602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-22 07:50:22.455157: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-22 07:50:22.455304: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-22 07:50:22.455490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.456100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-07-22 07:50:22.456145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-22 07:50:22.456171: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-22 07:50:22.456188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-22 07:50:22.456204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-22 07:50:22.456220: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-22 07:50:22.456236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-22 07:50:22.456267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-22 07:50:22.456283: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-22 07:50:22.456357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.457005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:22.457572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-22 07:50:22.457632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-22 07:50:23.043566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-22 07:50:23.043610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-07-22 07:50:23.043619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-07-22 07:50:23.043917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:23.044745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:23.045407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-22 07:50:23.045981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "image_paths, mask_paths = load_data(OUTPUT_DIR)\n",
    "dataset = create_dataset(image_paths, mask_paths)\n",
    "train, val, test = test_train_val_split(dataset, len(image_paths), train_percent, val_percent, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ffb5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:23.839573Z",
     "iopub.status.busy": "2022-07-22T07:50:23.838891Z",
     "iopub.status.idle": "2022-07-22T07:50:23.860089Z",
     "shell.execute_reply": "2022-07-22T07:50:23.859185Z"
    },
    "papermill": {
     "duration": 0.056034,
     "end_time": "2022-07-22T07:50:23.862035",
     "exception": false,
     "start_time": "2022-07-22T07:50:23.806001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def conv_bn(x, filters, kernel_size=3, strides=1):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding='same',\n",
    "                               use_bias=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dilated_conv_bn(x, filters, kernel_size=3, rate=1):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding='same',\n",
    "                               use_bias=True,\n",
    "                               dilation_rate=(rate,rate))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dilated_spatial_pyramidal_pooling_conv(x, filters, kernel_size=3):\n",
    "    x2 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=3,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(2,2))(x)\n",
    "    x4 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=3,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(4,4))(x)\n",
    "    x8 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=3,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(8,8))(x)\n",
    "    x16 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                 kernel_size=3,\n",
    "                                 padding='same',\n",
    "                                 use_bias=True,\n",
    "                                 dilation_rate=(16,16))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x, x2, x4, x8, x16])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=1,\n",
    "                               padding='same',\n",
    "                               use_bias=True)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def model(x):\n",
    "    # Encoder\n",
    "    x = conv_bn(x, filters=16)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x1 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=2)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x2 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=4)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x4 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=8)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x8 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=16)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = conv_bn(x, filters=32)\n",
    "\n",
    "    # Decoder\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x8, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x4, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x2, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x1, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "\n",
    "    # Number of filters = number of classes\n",
    "    x = tf.keras.layers.Conv2D(filters=NUM_CLASSES, kernel_size=1, strides=1, activation='softmax')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b51dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:23.926818Z",
     "iopub.status.busy": "2022-07-22T07:50:23.926522Z",
     "iopub.status.idle": "2022-07-22T07:50:23.982170Z",
     "shell.execute_reply": "2022-07-22T07:50:23.981339Z"
    },
    "papermill": {
     "duration": 0.090386,
     "end_time": "2022-07-22T07:50:23.984117",
     "exception": false,
     "start_time": "2022-07-22T07:50:23.893731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file is taken \n",
    "# from https://github.com/mlyg/unified-focal-loss/blob/main/loss_functions.py\n",
    "# Edited to make it compatible with multi-class segmentation\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper function to enable loss function to be flexibly used for \n",
    "# both 2D or 3D image segmentation - source: https://github.com/frankkramer-lab/MIScnn\n",
    "def identify_axis(shape):\n",
    "    # Three dimensional\n",
    "    if len(shape) == 5 : return [1,2,3]\n",
    "    # Two dimensional\n",
    "    elif len(shape) == 4 : return [1,2]\n",
    "    # Exception - Unknown\n",
    "    else : raise ValueError('Metric: Shape of tensor is neither 2D or 3D.')\n",
    "\n",
    "################################\n",
    "#       Dice coefficient       #\n",
    "################################\n",
    "def dice_coefficient(delta = 0.5, smooth = 0.000001):\n",
    "    \"\"\"The Dice similarity coefficient, also known as the Sørensen–Dice index or simply Dice coefficient, is a statistical tool which measures the similarity between two sets of data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.5\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)   \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        dice = K.mean(dice_class)\n",
    "\n",
    "        return dice\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#           Dice loss          #\n",
    "################################\n",
    "def dice_loss(delta = 0.5, smooth = 0.000001):\n",
    "    \"\"\"Dice loss originates from Sørensen–Dice coefficient, which is a statistic developed in 1940s to gauge the similarity between two samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.5\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        # Calculate Dice score\n",
    "        dice_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        dice_loss = K.mean(1-dice_class)\n",
    "\n",
    "        return dice_loss\n",
    "        \n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#         Tversky loss         #\n",
    "################################\n",
    "def tversky_loss(delta = 0.7, smooth = 0.000001):\n",
    "    \"\"\"Tversky loss function for image segmentation using 3D fully convolutional deep networks\n",
    "\tLink: https://arxiv.org/abs/1706.05721\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)   \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        tversky_loss = K.mean(1-tversky_class)\n",
    "\n",
    "        return tversky_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#          Combo loss          #\n",
    "################################\n",
    "def combo_loss(alpha=0.5,beta=0.5):\n",
    "    \"\"\"Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation\n",
    "    Link: https://arxiv.org/abs/1805.02798\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional\n",
    "        controls weighting of dice and cross-entropy loss., by default 0.5\n",
    "    beta : float, optional\n",
    "        beta > 0.5 penalises false negatives more than false positives., by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        dice = dice_coefficient()(y_true, y_pred)\n",
    "        # axis = identify_axis(y_true.get_shape())\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        if beta is not None:\n",
    "            beta_weight = np.array([beta, 1-beta])\n",
    "            cross_entropy = beta_weight * cross_entropy\n",
    "        # sum over classes\n",
    "        cross_entropy = K.mean(K.sum(cross_entropy, axis=[-1]))\n",
    "        if alpha is not None:\n",
    "            combo_loss = (alpha * cross_entropy) - ((1 - alpha) * dice)\n",
    "        else:\n",
    "            combo_loss = cross_entropy - dice\n",
    "        return combo_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#      Focal Tversky loss      #\n",
    "################################\n",
    "def focal_tversky_loss(delta=0.7, gamma=0.75, smooth=0.000001):\n",
    "    \"\"\"A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation\n",
    "    Link: https://arxiv.org/abs/1810.07842\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon) \n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        focal_tversky_loss = K.mean(K.pow((1-tversky_class), gamma))\n",
    "\t\n",
    "        return focal_tversky_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#          Focal loss          #\n",
    "################################\n",
    "def focal_loss(alpha=None, gamma_f=2.):\n",
    "    \"\"\"Focal loss is used to address the issue of the class imbalance problem. A modulation term applied to the Cross-Entropy loss function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional\n",
    "        controls relative weight of false positives and false negatives. alpha > 0.5 penalises false negatives more than false positives, by default None\n",
    "    gamma_f : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 2.\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # axis = identify_axis(y_true.get_shape())\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        if alpha is not None:\n",
    "            alpha_weight = np.array(alpha, dtype=np.float32)\n",
    "            focal_loss = alpha_weight * K.pow(1 - y_pred, gamma_f) * cross_entropy\n",
    "        else:\n",
    "            focal_loss = K.pow(1 - y_pred, gamma_f) * cross_entropy\n",
    "\n",
    "        focal_loss = K.mean(K.sum(focal_loss, axis=[-1]))\n",
    "        return focal_loss\n",
    "        \n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#     Symmetric Focal loss     #\n",
    "################################\n",
    "def symmetric_focal_loss(delta=0.7, gamma=2.):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        Focal Tversky loss' focal parameter controls degree of down-weighting of easy examples, by default 2.0\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "\n",
    "        # axis = identify_axis(y_true.get_shape())  \n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        #calculate losses separately for each class\n",
    "        background_ce = K.pow(1 - y_pred[:,:,:,0], gamma) * cross_entropy[:,:,:,0]\n",
    "        background_ce =  (1 - delta) * background_ce\n",
    "\n",
    "        # This section is modified for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_ce = [background_ce]\n",
    "        \n",
    "        for i in range(1, numClasses):\n",
    "            class_ce = cross_entropy[:,:,:,i]\n",
    "            class_ce = delta * class_ce\n",
    "            list_of_class_ce.append(class_ce)\n",
    "\n",
    "        loss = K.mean(K.sum(tf.stack(list_of_class_ce, axis=-1), axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "#################################\n",
    "# Symmetric Focal Tversky loss  #\n",
    "#################################\n",
    "def symmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for multi-class segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon)/(tp + delta*fn + (1-delta)*fp + epsilon)\n",
    "\n",
    "        #calculate losses separately for each class, enhancing both classes\n",
    "        background_dice = (1-dice_class[:,0]) * K.pow(1-dice_class[:,0], -gamma)\n",
    "\n",
    "        # modify this section below for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_dice = [background_dice]\n",
    "        for i in range(1, numClasses):\n",
    "            class_dice = (1-dice_class[:,i]) * K.pow(1-dice_class[:,i], -gamma)\n",
    "            list_of_class_dice.append(class_dice)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack(list_of_class_dice, axis=-1))\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#     Asymmetric Focal loss    #\n",
    "################################\n",
    "def asymmetric_focal_loss(delta=0.7, gamma=2.):\n",
    "    \"\"\"For Imbalanced datasets (multi-class)\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        Focal Tversky loss' focal parameter controls degree of down-weighting of easy examples, by default 2.0\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())  \n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        #calculate losses separately for each class, only suppressing background class\n",
    "        background_ce = K.pow(1 - y_pred[:,:,:,0], gamma) * cross_entropy[:,:,:,0]\n",
    "        background_ce =  (1 - delta) * background_ce\n",
    "\n",
    "        # This section is modified for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_ce = [background_ce]\n",
    "\n",
    "        for i in range(1, numClasses):\n",
    "            class_ce = cross_entropy[:,:,:,i]\n",
    "            class_ce = delta * class_ce\n",
    "            list_of_class_ce.append(class_ce)\n",
    "\n",
    "        loss = K.mean(K.sum(tf.stack(list_of_class_ce, axis=-1), axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "#################################\n",
    "# Asymmetric Focal Tversky loss #\n",
    "#################################\n",
    "def asymmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for multi-class segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon)/(tp + delta*fn + (1-delta)*fp + epsilon)\n",
    "\n",
    "        #calculate losses separately for each class, enhancing both classes\n",
    "        background_dice = (1-dice_class[:,0])\n",
    "\n",
    "        # modify this section below for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_dice = [background_dice]\n",
    "        for i in range(1, numClasses):\n",
    "            class_dice = (1-dice_class[:,i]) * K.pow(1-dice_class[:,i], -gamma)\n",
    "            list_of_class_dice.append(class_dice)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack(list_of_class_dice, axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "###########################################\n",
    "#      Symmetric Unified Focal loss       #\n",
    "###########################################\n",
    "def sym_unified_focal_loss(weight=0.5, delta=0.6, gamma=0.5):\n",
    "    \"\"\"The Unified Focal loss is a new compound loss function that unifies Dice-based and cross entropy-based loss functions into a single framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight : float, optional\n",
    "        represents lambda parameter and controls weight given to symmetric Focal Tversky loss and symmetric Focal loss, by default 0.5\n",
    "    delta : float, optional\n",
    "        controls weight given to each class, by default 0.6\n",
    "    gamma : float, optional\n",
    "        focal parameter controls the degree of background suppression and foreground enhancement, by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        symmetric_ftl = symmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        symmetric_fl = symmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        if weight is not None:\n",
    "            return (weight * symmetric_ftl) + ((1-weight) * symmetric_fl)  \n",
    "        else:\n",
    "            return symmetric_ftl + symmetric_fl\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "###########################################\n",
    "#      Asymmetric Unified Focal loss      #\n",
    "###########################################\n",
    "def asym_unified_focal_loss(weight=0.5, delta=0.6, gamma=0.5):\n",
    "    \"\"\"The Unified Focal loss is a new compound loss function that unifies Dice-based and cross entropy-based loss functions into a single framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight : float, optional\n",
    "        represents lambda parameter and controls weight given to asymmetric Focal Tversky loss and asymmetric Focal loss, by default 0.5\n",
    "    delta : float, optional\n",
    "        controls weight given to each class, by default 0.6\n",
    "    gamma : float, optional\n",
    "        focal parameter controls the degree of background suppression and foreground enhancement, by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        asymmetric_ftl = asymmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        asymmetric_fl = asymmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        if weight is not None:\n",
    "            return (weight * asymmetric_ftl) + ((1-weight) * asymmetric_fl)  \n",
    "        else:\n",
    "            return asymmetric_ftl + asymmetric_fl\n",
    "\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36aa7f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:24.049311Z",
     "iopub.status.busy": "2022-07-22T07:50:24.048568Z",
     "iopub.status.idle": "2022-07-22T07:50:24.057189Z",
     "shell.execute_reply": "2022-07-22T07:50:24.056047Z"
    },
    "papermill": {
     "duration": 0.043334,
     "end_time": "2022-07-22T07:50:24.059309",
     "exception": false,
     "start_time": "2022-07-22T07:50:24.015975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#         OneHot MeanIoU       #\n",
    "################################\n",
    "class OneHotMeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    '''\n",
    "    Custom metric to calculate OneHotMeanIoU\n",
    "    as the keras version is not available in tf 2.6\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        name=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        super(OneHotMeanIoU, self).__init__(\n",
    "            num_classes=num_classes,\n",
    "            name=name,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Accumulates the confusion matrix statistics.\n",
    "        Args:\n",
    "          y_true: The ground truth values.\n",
    "          y_pred: The predicted values.\n",
    "          sample_weight: Optional weighting of each example. Defaults to 1. Can be a\n",
    "            `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n",
    "            be broadcastable to `y_true`.\n",
    "        Returns:\n",
    "          Update op.\n",
    "        \"\"\"\n",
    "        # Select max hot-encoding channels to convert into all-class format\n",
    "        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "        \n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c526c2b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:24.123178Z",
     "iopub.status.busy": "2022-07-22T07:50:24.122917Z",
     "iopub.status.idle": "2022-07-22T07:50:24.688851Z",
     "shell.execute_reply": "2022-07-22T07:50:24.687906Z"
    },
    "papermill": {
     "duration": 0.601008,
     "end_time": "2022-07-22T07:50:24.691697",
     "exception": false,
     "start_time": "2022-07-22T07:50:24.090689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input = tf.keras.layers.Input(shape=[TARGET_SIZE, TARGET_SIZE, 3])\n",
    "output = model(input)\n",
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd46122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:24.758924Z",
     "iopub.status.busy": "2022-07-22T07:50:24.758594Z",
     "iopub.status.idle": "2022-07-22T07:50:24.814705Z",
     "shell.execute_reply": "2022-07-22T07:50:24.813805Z"
    },
    "papermill": {
     "duration": 0.091125,
     "end_time": "2022-07-22T07:50:24.816825",
     "exception": false,
     "start_time": "2022-07-22T07:50:24.725700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "# 0 is background, 1 is building, 2 is woodland, 3 is water, 4 is road\n",
    "model.compile(optimizer='adam', loss=asym_unified_focal_loss(), \n",
    "              metrics=[OneHotMeanIoU(NUM_CLASSES, name='MeanIoU'),\n",
    "                       Precision(name='bgrPcsn', class_id=0),\n",
    "                       Precision(name='bldPcsn', class_id=1),\n",
    "                       Precision(name='wldPcsn', class_id=2),\n",
    "                       Precision(name='wtrPcsn', class_id=3),\n",
    "                       Precision(name='roadPcsn', class_id=4),\n",
    "                       Recall(name='bgrRcl', class_id=0),\n",
    "                       Recall(name='bldRcl', class_id=1),\n",
    "                       Recall(name='wldRcl', class_id=2),\n",
    "                       Recall(name='wtrRcl', class_id=3),\n",
    "                       Recall(name='roadRcl', class_id=4)\n",
    "                      ])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882b3c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T07:50:24.882492Z",
     "iopub.status.busy": "2022-07-22T07:50:24.881639Z",
     "iopub.status.idle": "2022-07-22T13:12:02.881629Z",
     "shell.execute_reply": "2022-07-22T13:12:02.880654Z"
    },
    "papermill": {
     "duration": 19299.372282,
     "end_time": "2022-07-22T13:12:04.220777",
     "exception": false,
     "start_time": "2022-07-22T07:50:24.848495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 07:50:24.901574: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-22 07:50:24.902971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000179999 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 07:50:31.710109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-22 07:50:37.948889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-22 07:50:38.823223: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-22 07:50:39.927202: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.42GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-22 07:50:41.082237: W tensorflow/core/common_runtime/bfc_allocator.cc:248] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.69GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324/1324 [==============================] - 1388s 1s/step - loss: 0.5604 - MeanIoU: 0.3625 - bgrPcsn: 0.8585 - bldPcsn: 0.4425 - wldPcsn: 0.7600 - wtrPcsn: 0.4959 - roadPcsn: 0.3839 - bgrRcl: 0.7424 - bldRcl: 0.1324 - wldRcl: 0.8100 - wtrRcl: 0.2124 - roadRcl: 0.1165 - val_loss: 0.5311 - val_MeanIoU: 0.4099 - val_bgrPcsn: 0.8506 - val_bldPcsn: 0.6886 - val_wldPcsn: 0.8274 - val_wtrPcsn: 0.8015 - val_roadPcsn: 0.2737 - val_bgrRcl: 0.8613 - val_bldRcl: 0.2449 - val_wldRcl: 0.8773 - val_wtrRcl: 0.1418 - val_roadRcl: 0.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 08:13:36.159742: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "1324/1324 [==============================] - 1366s 1s/step - loss: 0.4881 - MeanIoU: 0.5234 - bgrPcsn: 0.9012 - bldPcsn: 0.6254 - wldPcsn: 0.8401 - wtrPcsn: 0.6997 - roadPcsn: 0.4958 - bgrRcl: 0.8508 - bldRcl: 0.3941 - wldRcl: 0.8947 - wtrRcl: 0.6249 - roadRcl: 0.3101 - val_loss: 0.4755 - val_MeanIoU: 0.5769 - val_bgrPcsn: 0.8926 - val_bldPcsn: 0.5031 - val_wldPcsn: 0.9142 - val_wtrPcsn: 0.8344 - val_roadPcsn: 0.3402 - val_bgrRcl: 0.8904 - val_bldRcl: 0.6509 - val_wldRcl: 0.8474 - val_wtrRcl: 0.7778 - val_roadRcl: 0.4983\n",
      "Epoch 3/15\n",
      "1324/1324 [==============================] - 1366s 1s/step - loss: 0.4663 - MeanIoU: 0.5924 - bgrPcsn: 0.9233 - bldPcsn: 0.6631 - wldPcsn: 0.8615 - wtrPcsn: 0.7762 - roadPcsn: 0.5457 - bgrRcl: 0.8732 - bldRcl: 0.5505 - wldRcl: 0.9170 - wtrRcl: 0.7436 - roadRcl: 0.3959 - val_loss: 0.4825 - val_MeanIoU: 0.5591 - val_bgrPcsn: 0.9007 - val_bldPcsn: 0.7713 - val_wldPcsn: 0.8341 - val_wtrPcsn: 0.7733 - val_roadPcsn: 0.5711 - val_bgrRcl: 0.8668 - val_bldRcl: 0.4643 - val_wldRcl: 0.9162 - val_wtrRcl: 0.5896 - val_roadRcl: 0.3826\n",
      "Epoch 4/15\n",
      "1324/1324 [==============================] - 1367s 1s/step - loss: 0.4544 - MeanIoU: 0.6305 - bgrPcsn: 0.9354 - bldPcsn: 0.6913 - wldPcsn: 0.8738 - wtrPcsn: 0.8087 - roadPcsn: 0.5930 - bgrRcl: 0.8868 - bldRcl: 0.6182 - wldRcl: 0.9286 - wtrRcl: 0.7897 - roadRcl: 0.4551 - val_loss: 0.4746 - val_MeanIoU: 0.5751 - val_bgrPcsn: 0.9230 - val_bldPcsn: 0.5602 - val_wldPcsn: 0.8612 - val_wtrPcsn: 0.6033 - val_roadPcsn: 0.5940 - val_bgrRcl: 0.8300 - val_bldRcl: 0.7547 - val_wldRcl: 0.9000 - val_wtrRcl: 0.8089 - val_roadRcl: 0.4415\n",
      "Epoch 5/15\n",
      "1324/1324 [==============================] - 1367s 1s/step - loss: 0.4484 - MeanIoU: 0.6490 - bgrPcsn: 0.9373 - bldPcsn: 0.7068 - wldPcsn: 0.8813 - wtrPcsn: 0.8325 - roadPcsn: 0.6128 - bgrRcl: 0.8950 - bldRcl: 0.6460 - wldRcl: 0.9316 - wtrRcl: 0.8044 - roadRcl: 0.4836 - val_loss: 0.4673 - val_MeanIoU: 0.5583 - val_bgrPcsn: 0.9496 - val_bldPcsn: 0.3735 - val_wldPcsn: 0.8546 - val_wtrPcsn: 0.6283 - val_roadPcsn: 0.6562 - val_bgrRcl: 0.8246 - val_bldRcl: 0.8790 - val_wldRcl: 0.9477 - val_wtrRcl: 0.8311 - val_roadRcl: 0.3204\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/15\n",
      "1324/1324 [==============================] - 1371s 1s/step - loss: 0.4369 - MeanIoU: 0.6864 - bgrPcsn: 0.9471 - bldPcsn: 0.7374 - wldPcsn: 0.8907 - wtrPcsn: 0.8798 - roadPcsn: 0.6464 - bgrRcl: 0.9071 - bldRcl: 0.6996 - wldRcl: 0.9406 - wtrRcl: 0.8416 - roadRcl: 0.5337 - val_loss: 0.4260 - val_MeanIoU: 0.7189 - val_bgrPcsn: 0.9563 - val_bldPcsn: 0.7867 - val_wldPcsn: 0.8941 - val_wtrPcsn: 0.9158 - val_roadPcsn: 0.7144 - val_bgrRcl: 0.9192 - val_bldRcl: 0.7207 - val_wldRcl: 0.9511 - val_wtrRcl: 0.8932 - val_roadRcl: 0.5164\n",
      "Epoch 7/15\n",
      "1324/1324 [==============================] - 1371s 1s/step - loss: 0.4330 - MeanIoU: 0.6980 - bgrPcsn: 0.9485 - bldPcsn: 0.7431 - wldPcsn: 0.8933 - wtrPcsn: 0.8916 - roadPcsn: 0.6578 - bgrRcl: 0.9129 - bldRcl: 0.7170 - wldRcl: 0.9417 - wtrRcl: 0.8555 - roadRcl: 0.5491 - val_loss: 0.4256 - val_MeanIoU: 0.7204 - val_bgrPcsn: 0.9552 - val_bldPcsn: 0.7967 - val_wldPcsn: 0.8922 - val_wtrPcsn: 0.9102 - val_roadPcsn: 0.7155 - val_bgrRcl: 0.9161 - val_bldRcl: 0.7116 - val_wldRcl: 0.9500 - val_wtrRcl: 0.8881 - val_roadRcl: 0.5463\n",
      "Epoch 8/15\n",
      "1324/1324 [==============================] - 1372s 1s/step - loss: 0.4305 - MeanIoU: 0.7028 - bgrPcsn: 0.9507 - bldPcsn: 0.7453 - wldPcsn: 0.8960 - wtrPcsn: 0.8999 - roadPcsn: 0.6495 - bgrRcl: 0.9158 - bldRcl: 0.7236 - wldRcl: 0.9436 - wtrRcl: 0.8701 - roadRcl: 0.5414 - val_loss: 0.4245 - val_MeanIoU: 0.7239 - val_bgrPcsn: 0.9603 - val_bldPcsn: 0.7282 - val_wldPcsn: 0.8911 - val_wtrPcsn: 0.9379 - val_roadPcsn: 0.6078 - val_bgrRcl: 0.9115 - val_bldRcl: 0.7873 - val_wldRcl: 0.9529 - val_wtrRcl: 0.8949 - val_roadRcl: 0.6213\n",
      "Epoch 9/15\n",
      "1324/1324 [==============================] - 1369s 1s/step - loss: 0.4295 - MeanIoU: 0.7061 - bgrPcsn: 0.9515 - bldPcsn: 0.7527 - wldPcsn: 0.8970 - wtrPcsn: 0.9025 - roadPcsn: 0.6499 - bgrRcl: 0.9165 - bldRcl: 0.7331 - wldRcl: 0.9449 - wtrRcl: 0.8704 - roadRcl: 0.5426 - val_loss: 0.4238 - val_MeanIoU: 0.7249 - val_bgrPcsn: 0.9604 - val_bldPcsn: 0.7227 - val_wldPcsn: 0.8900 - val_wtrPcsn: 0.9287 - val_roadPcsn: 0.6617 - val_bgrRcl: 0.9126 - val_bldRcl: 0.8010 - val_wldRcl: 0.9542 - val_wtrRcl: 0.8940 - val_roadRcl: 0.5848\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 10/15\n",
      "1324/1324 [==============================] - 1370s 1s/step - loss: 0.4279 - MeanIoU: 0.7132 - bgrPcsn: 0.9537 - bldPcsn: 0.7513 - wldPcsn: 0.8971 - wtrPcsn: 0.9108 - roadPcsn: 0.6477 - bgrRcl: 0.9167 - bldRcl: 0.7371 - wldRcl: 0.9460 - wtrRcl: 0.8857 - roadRcl: 0.5646 - val_loss: 0.4219 - val_MeanIoU: 0.7334 - val_bgrPcsn: 0.9564 - val_bldPcsn: 0.7555 - val_wldPcsn: 0.9027 - val_wtrPcsn: 0.9379 - val_roadPcsn: 0.6779 - val_bgrRcl: 0.9238 - val_bldRcl: 0.7636 - val_wldRcl: 0.9473 - val_wtrRcl: 0.9039 - val_roadRcl: 0.5909\n",
      "Epoch 11/15\n",
      "1324/1324 [==============================] - 1370s 1s/step - loss: 0.4272 - MeanIoU: 0.7168 - bgrPcsn: 0.9535 - bldPcsn: 0.7521 - wldPcsn: 0.9000 - wtrPcsn: 0.9196 - roadPcsn: 0.6546 - bgrRcl: 0.9188 - bldRcl: 0.7337 - wldRcl: 0.9463 - wtrRcl: 0.8888 - roadRcl: 0.5680 - val_loss: 0.4213 - val_MeanIoU: 0.7287 - val_bgrPcsn: 0.9594 - val_bldPcsn: 0.7404 - val_wldPcsn: 0.9015 - val_wtrPcsn: 0.9274 - val_roadPcsn: 0.6528 - val_bgrRcl: 0.9215 - val_bldRcl: 0.7759 - val_wldRcl: 0.9504 - val_wtrRcl: 0.9012 - val_roadRcl: 0.5923\n",
      "Epoch 12/15\n",
      "1324/1324 [==============================] - 1372s 1s/step - loss: 0.4277 - MeanIoU: 0.7138 - bgrPcsn: 0.9530 - bldPcsn: 0.7536 - wldPcsn: 0.8971 - wtrPcsn: 0.9150 - roadPcsn: 0.6588 - bgrRcl: 0.9170 - bldRcl: 0.7249 - wldRcl: 0.9457 - wtrRcl: 0.8866 - roadRcl: 0.5634 - val_loss: 0.4217 - val_MeanIoU: 0.7335 - val_bgrPcsn: 0.9588 - val_bldPcsn: 0.7457 - val_wldPcsn: 0.9011 - val_wtrPcsn: 0.9381 - val_roadPcsn: 0.6687 - val_bgrRcl: 0.9204 - val_bldRcl: 0.7885 - val_wldRcl: 0.9530 - val_wtrRcl: 0.8972 - val_roadRcl: 0.5908\n",
      "Epoch 13/15\n",
      "1324/1324 [==============================] - 1372s 1s/step - loss: 0.4274 - MeanIoU: 0.7136 - bgrPcsn: 0.9529 - bldPcsn: 0.7604 - wldPcsn: 0.8972 - wtrPcsn: 0.9175 - roadPcsn: 0.6565 - bgrRcl: 0.9191 - bldRcl: 0.7301 - wldRcl: 0.9449 - wtrRcl: 0.8826 - roadRcl: 0.5521 - val_loss: 0.4218 - val_MeanIoU: 0.7334 - val_bgrPcsn: 0.9594 - val_bldPcsn: 0.7522 - val_wldPcsn: 0.8946 - val_wtrPcsn: 0.9373 - val_roadPcsn: 0.6841 - val_bgrRcl: 0.9193 - val_bldRcl: 0.7882 - val_wldRcl: 0.9525 - val_wtrRcl: 0.8972 - val_roadRcl: 0.5810\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 14/15\n",
      "1324/1324 [==============================] - 1372s 1s/step - loss: 0.4263 - MeanIoU: 0.7179 - bgrPcsn: 0.9533 - bldPcsn: 0.7598 - wldPcsn: 0.8983 - wtrPcsn: 0.9139 - roadPcsn: 0.6672 - bgrRcl: 0.9201 - bldRcl: 0.7510 - wldRcl: 0.9449 - wtrRcl: 0.8791 - roadRcl: 0.5652 - val_loss: 0.4215 - val_MeanIoU: 0.7320 - val_bgrPcsn: 0.9607 - val_bldPcsn: 0.7509 - val_wldPcsn: 0.8967 - val_wtrPcsn: 0.9393 - val_roadPcsn: 0.6756 - val_bgrRcl: 0.9192 - val_bldRcl: 0.7655 - val_wldRcl: 0.9550 - val_wtrRcl: 0.9043 - val_roadRcl: 0.5808\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "save_model_path = '/kaggle/working/checkpoint_6'\n",
    "\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=save_model_path, \n",
    "    monitor='val_MeanIoU', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "cb_earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_MeanIoU',\n",
    "    mode='max',\n",
    "    min_delta=0.001,\n",
    "    patience=4,\n",
    "    verbose=1\n",
    ")\n",
    "cb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_MeanIoU',\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "    \n",
    "history = model.fit(train.repeat(), \n",
    "                    steps_per_epoch=int(np.ceil(train_percent*len(image_paths) / float(BATCH_SIZE))),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val.repeat(),\n",
    "                    validation_steps=int(np.ceil(val_percent*len(image_paths) / float(BATCH_SIZE))),\n",
    "                    callbacks=[cp, cb_earlystop, cb_reducelr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eda2e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T13:12:06.843584Z",
     "iopub.status.busy": "2022-07-22T13:12:06.843070Z",
     "iopub.status.idle": "2022-07-22T13:12:20.739291Z",
     "shell.execute_reply": "2022-07-22T13:12:20.738132Z"
    },
    "papermill": {
     "duration": 15.2755,
     "end_time": "2022-07-22T13:12:20.742240",
     "exception": false,
     "start_time": "2022-07-22T13:12:05.466740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/model_7/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/saved_model.pb (deflated 92%)\r\n",
      "  adding: kaggle/working/model_7/assets/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/variables/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/variables/variables.data-00000-of-00001 (deflated 10%)\r\n",
      "  adding: kaggle/working/model_7/variables/variables.index (deflated 80%)\r\n"
     ]
    }
   ],
   "source": [
    "model.save('/kaggle/working/model_7')\n",
    "!zip -r model_7.zip /kaggle/working/model_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c68668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T13:12:23.625821Z",
     "iopub.status.busy": "2022-07-22T13:12:23.625440Z",
     "iopub.status.idle": "2022-07-22T13:12:23.635977Z",
     "shell.execute_reply": "2022-07-22T13:12:23.635105Z"
    },
    "papermill": {
     "duration": 1.552322,
     "end_time": "2022-07-22T13:12:23.638048",
     "exception": false,
     "start_time": "2022-07-22T13:12:22.085726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('/kaggle/input/model6/model_6/', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06e33ddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T13:12:26.229305Z",
     "iopub.status.busy": "2022-07-22T13:12:26.228713Z",
     "iopub.status.idle": "2022-07-22T13:15:18.008627Z",
     "shell.execute_reply": "2022-07-22T13:15:18.007674Z"
    },
    "papermill": {
     "duration": 173.118707,
     "end_time": "2022-07-22T13:15:18.011369",
     "exception": false,
     "start_time": "2022-07-22T13:12:24.892662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 172s 306ms/step - loss: 0.4210 - MeanIoU: 0.7325 - bgrPcsn: 0.9588 - bldPcsn: 0.7599 - wldPcsn: 0.8981 - wtrPcsn: 0.9342 - roadPcsn: 0.6744 - bgrRcl: 0.9189 - bldRcl: 0.7780 - wldRcl: 0.9535 - wtrRcl: 0.8876 - roadRcl: 0.5964\n",
      "Restored model, accuracy: 73.25%\n"
     ]
    }
   ],
   "source": [
    "loss, acc, *is_anything_else_being_returned = model.evaluate(test, verbose=1, batch_size=BATCH_SIZE)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b278afd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T13:15:20.887906Z",
     "iopub.status.busy": "2022-07-22T13:15:20.887474Z",
     "iopub.status.idle": "2022-07-22T13:15:20.892612Z",
     "shell.execute_reply": "2022-07-22T13:15:20.891668Z"
    },
    "papermill": {
     "duration": 1.3776,
     "end_time": "2022-07-22T13:15:20.894982",
     "exception": false,
     "start_time": "2022-07-22T13:15:19.517382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def display(display_list):\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "\n",
    "#     title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "#     for i in range(len(display_list)):\n",
    "#         plt.subplot(1, len(display_list), i+1)\n",
    "#         plt.title(title[i])\n",
    "#         plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# def create_mask(mask):\n",
    "#     condensed_mask = tf.math.argmax(mask, axis=-1)\n",
    "#     condensed_mask = condensed_mask[..., tf.newaxis]\n",
    "#     return condensed_mask[0]\n",
    "\n",
    "# def show_predictions(model, dataset=None, num=1):\n",
    "#     for image, mask in dataset.take(num):\n",
    "#         pred_mask = model.predict(image)\n",
    "#         display([image[0], create_mask(mask), create_mask(pred_mask)])\n",
    "\n",
    "# show_predictions(model, test, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a81110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T13:15:23.541499Z",
     "iopub.status.busy": "2022-07-22T13:15:23.540763Z",
     "iopub.status.idle": "2022-07-22T13:15:23.550164Z",
     "shell.execute_reply": "2022-07-22T13:15:23.549103Z"
    },
    "papermill": {
     "duration": 1.366714,
     "end_time": "2022-07-22T13:15:23.552674",
     "exception": false,
     "start_time": "2022-07-22T13:15:22.185960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img_name = 'N-33-60-D-c-4-2'\n",
    "# IMAGE_PATH = '../input/landcoverai/images/{}.tif'.format(img_name)\n",
    "# LABEL_PATH = '../input/landcoverai/masks/{}.tif'.format(img_name)\n",
    "\n",
    "# def from_one_hot_to_rgb_bkup(class_indexes, palette=None):\n",
    "#     \"\"\" \n",
    "#     https://stackoverflow.com/a/60811084/6328456\n",
    "#     Assign a different color to each class in the input tensor \n",
    "#     \"\"\"\n",
    "#     if palette is None:\n",
    "#         palette = tf.constant(\n",
    "#             [[0, 0, 0],\n",
    "#             [31, 12, 33],\n",
    "#             [13, 26, 33],\n",
    "#             [21, 76, 22],\n",
    "#             [22, 54, 66]]\n",
    "#         , dtype=tf.int32)\n",
    "\n",
    "#     H, W, _ = class_indexes.shape\n",
    "#     class_indexes = tf.cast(class_indexes, tf.int32)\n",
    "\n",
    "#     color_image = tf.gather(palette, class_indexes)\n",
    "#     color_image = tf.reshape(color_image, [H, W, 3])\n",
    "\n",
    "#     color_image = tf.cast(color_image, dtype=tf.float32)\n",
    "#     return color_image\n",
    "\n",
    "# def pad_image_to_tile_multiple(image3, tile_size, padding=\"CONSTANT\"):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Pad an image to a multiple of the tile size.\n",
    "#     Input:\n",
    "#         image3: A 3D tensor with shape (H,W,C)\n",
    "#         tile_size: Tuple denoting size of the tiles.\n",
    "#         padding: Padding type for tf.pad command.\n",
    "#     Returns:\n",
    "#         A padded tensor.\n",
    "#     '''\n",
    "#     original_image_size = image3.shape\n",
    "#     image_size = tf.shape(image3)[0:2]\n",
    "#     padding_ = tf.cast(tf.math.ceil(image_size / tile_size), tf.int32) * tile_size - image_size\n",
    "#     return original_image_size, tf.pad(image3, [[0, padding_[0]], [0, padding_[1]], [0, 0]], padding)\n",
    "\n",
    "# def remove_image_padding(image3, original_img_shape):\n",
    "#     image3 = image3[0:original_img_shape[0], 0:original_img_shape[1], :]\n",
    "#     return image3\n",
    "\n",
    "# def split_image(image3, tile_size):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Split an image into tiles. Converts a 3D tensor with shape (H,W,C) to a 4D tensor with shape (B,H,W,C).\n",
    "#     Input:\n",
    "#         image3: A 3D tensor with shape (H,W,C)\n",
    "#         tile_size: Tuple denoting size of the tiles.\n",
    "#     Returns:\n",
    "#         A 4D tensor with shape (B,H,W,C)\n",
    "#     '''\n",
    "#     image_shape = tf.shape(image3)\n",
    "#     tile_rows = tf.reshape(image3, [image_shape[0], -1, tile_size[1], image_shape[2]])\n",
    "#     serial_tiles = tf.transpose(tile_rows, [1, 0, 2, 3])\n",
    "#     return tf.reshape(serial_tiles, [-1, tile_size[1], tile_size[0], image_shape[2]])\n",
    "\n",
    "# def unsplit_image(tiles4, image_shape):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Unsplit a tiles into an image. Converts a 4D tensor with [B,H,W,C] to a 3D tensor with [H,W,C].\n",
    "#     Input:\n",
    "#         tiles4: A 4D tensor with shape (B,H,W,C)\n",
    "#         image_shape: Tuple denoting size of the image.\n",
    "#     Returns:\n",
    "#         A 3D tensor with shape (H,W,C)\n",
    "#     '''\n",
    "#     tile_width = tf.shape(tiles4)[1]\n",
    "#     serialized_tiles = tf.reshape(tiles4, [-1, image_shape[0], tile_width, image_shape[2]])\n",
    "#     rowwise_tiles = tf.transpose(serialized_tiles, [1, 0, 2, 3])\n",
    "#     return tf.reshape(rowwise_tiles, [image_shape[0], image_shape[1], image_shape[2]])\n",
    "\n",
    "# # Read image and convert to tensor\n",
    "# img = cv2.imread(IMAGE_PATH)\n",
    "# label = cv2.imread(LABEL_PATH, cv2.IMREAD_UNCHANGED)\n",
    "# img = tf.convert_to_tensor(img, tf.float32)\n",
    "# label = tf.convert_to_tensor(label, tf.float32)\n",
    "# label = label[..., tf.newaxis]\n",
    "\n",
    "# # Pad the image and label\n",
    "# original_label_shape, _ = pad_image_to_tile_multiple(label, [256, 256])\n",
    "# padded_label_shape = _.shape\n",
    "# original_img_shape, img = pad_image_to_tile_multiple(img, [256, 256])\n",
    "\n",
    "# # Split the padded image into batches and pad the batches\n",
    "# tiles = split_image(img, [256, 256])\n",
    "\n",
    "# # pred_masks = []\n",
    "# # for tile in tf.unstack(tiles):\n",
    "# #     plt.figure(figsize=(10,10))\n",
    "# #     tile = tile[tf.newaxis,...]\n",
    "# #     pred_mask = model.predict(tile)\n",
    "# #     # Reduce the multi channel output to single channel (1,H,W)\n",
    "# #     pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "# #     # Expand dimension to (1,H,W,1)\n",
    "# #     pred_mask = pred_mask[...,tf.newaxis]\n",
    "# #     plt.imshow(tf.keras.utils.array_to_img(pred_mask[0]))\n",
    "# #     pred_masks.append(pred_mask)\n",
    "# # pred_masks = tf.concat(pred_masks, axis=0)\n",
    "# pred_masks = model.predict(tiles)\n",
    "# pred_masks = tf.math.argmax(pred_masks, axis=-1)\n",
    "# pred_masks = pred_masks[...,tf.newaxis]\n",
    "# pred_mask = unsplit_image(pred_masks, padded_label_shape)\n",
    "\n",
    "# # Remove the padding from the image and mask\n",
    "# img = remove_image_padding(img, original_img_shape)\n",
    "# pred_mask = remove_image_padding(pred_mask, original_label_shape)\n",
    "\n",
    "# # print(\"Mask\")\n",
    "# # tf.print(pred_mask, summarize=3)\n",
    "# # print(\"Label\")\n",
    "# # tf.print(label, summarize=3)\n",
    "\n",
    "# # Convert the masks to a uint8 image\n",
    "# label = from_one_hot_to_rgb_bkup(label)\n",
    "# pred_mask = from_one_hot_to_rgb_bkup(pred_mask)\n",
    "# label = tf.keras.utils.array_to_img(label)\n",
    "# pred_mask = tf.keras.utils.array_to_img(pred_mask)\n",
    "\n",
    "# # Save as png\n",
    "# # img = tf.io.encode_png(tf.cast(img, tf.uint8))\n",
    "# # tf.io.write_file('{}_0.png'.format(img_name), img)\n",
    "# label.save('{}_label.png'.format(img_name))\n",
    "# pred_mask.save('{}_predMask.png'.format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015abdd",
   "metadata": {
    "papermill": {
     "duration": 1.347848,
     "end_time": "2022-07-22T13:15:26.241215",
     "exception": false,
     "start_time": "2022-07-22T13:15:24.893367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19752.444229,
   "end_time": "2022-07-22T13:15:30.730247",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-22T07:46:18.286018",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
