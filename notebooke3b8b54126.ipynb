{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d837b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:19:47.596593Z",
     "iopub.status.busy": "2022-07-24T12:19:47.596108Z",
     "iopub.status.idle": "2022-07-24T12:21:04.343966Z",
     "shell.execute_reply": "2022-07-24T12:21:04.342755Z"
    },
    "papermill": {
     "duration": 76.759523,
     "end_time": "2022-07-24T12:21:04.347757",
     "exception": false,
     "start_time": "2022-07-24T12:19:47.588234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.1\r\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.3/394.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.37.1)\r\n",
      "Collecting typing-extensions~=3.7.4\r\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.12)\r\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (2.6.0)\r\n",
      "Collecting absl-py~=0.10\r\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.2)\r\n",
      "Collecting wrapt~=1.12.1\r\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.6.3)\r\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (1.1.0)\r\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.3.0)\r\n",
      "Collecting h5py~=2.10.0\r\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\r\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting six~=1.15.0\r\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (3.19.4)\r\n",
      "Collecting gast==0.3.3\r\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\r\n",
      "Collecting numpy~=1.19.2\r\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.4.1) (0.2.0)\r\n",
      "Collecting grpcio~=1.32.0\r\n",
      "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.1.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.27.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (59.8.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.12.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.6.15)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\r\n",
      "Building wheels for collected packages: wrapt\r\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=77048 sha256=469c4c9c3df0bac140e0c53e06c27257aa8d84d3702e30823b37788ad47cac28\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\r\n",
      "Successfully built wrapt\r\n",
      "Installing collected packages: wrapt, typing-extensions, tensorflow-estimator, six, numpy, gast, h5py, grpcio, absl-py, tensorflow\r\n",
      "  Attempting uninstall: wrapt\r\n",
      "    Found existing installation: wrapt 1.14.1\r\n",
      "    Uninstalling wrapt-1.14.1:\r\n",
      "      Successfully uninstalled wrapt-1.14.1\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.1.1\r\n",
      "    Uninstalling typing_extensions-4.1.1:\r\n",
      "      Successfully uninstalled typing_extensions-4.1.1\r\n",
      "  Attempting uninstall: tensorflow-estimator\r\n",
      "    Found existing installation: tensorflow-estimator 2.6.0\r\n",
      "    Uninstalling tensorflow-estimator-2.6.0:\r\n",
      "      Successfully uninstalled tensorflow-estimator-2.6.0\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.16.0\r\n",
      "    Uninstalling six-1.16.0:\r\n",
      "      Successfully uninstalled six-1.16.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "    Uninstalling numpy-1.21.6:\r\n",
      "      Successfully uninstalled numpy-1.21.6\r\n",
      "  Attempting uninstall: gast\r\n",
      "    Found existing installation: gast 0.4.0\r\n",
      "    Uninstalling gast-0.4.0:\r\n",
      "      Successfully uninstalled gast-0.4.0\r\n",
      "  Attempting uninstall: h5py\r\n",
      "    Found existing installation: h5py 3.1.0\r\n",
      "    Uninstalling h5py-3.1.0:\r\n",
      "      Successfully uninstalled h5py-3.1.0\r\n",
      "  Attempting uninstall: grpcio\r\n",
      "    Found existing installation: grpcio 1.43.0\r\n",
      "    Uninstalling grpcio-1.43.0:\r\n",
      "      Successfully uninstalled grpcio-1.43.0\r\n",
      "  Attempting uninstall: absl-py\r\n",
      "    Found existing installation: absl-py 1.0.0\r\n",
      "    Uninstalling absl-py-1.0.0:\r\n",
      "      Successfully uninstalled absl-py-1.0.0\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.6.4\r\n",
      "    Uninstalling tensorflow-2.6.4:\r\n",
      "      Successfully uninstalled tensorflow-2.6.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "dask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "tfx-bsl 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15.5, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-transform 1.8.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.4.1 which is incompatible.\r\n",
      "starlette 0.19.1 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "rich 12.4.4 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pytorch-lightning 1.6.4 requires typing-extensions>=4.0.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pytools 2022.1.12 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pylint 2.14.4 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.2 which is incompatible.\r\n",
      "optax 0.1.2 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "nnabla 1.29.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "grpcio-status 1.46.3 requires grpcio>=1.46.3, but you have grpcio 1.32.0 which is incompatible.\r\n",
      "google-cloud-pubsub 2.12.1 requires grpcio<2.0dev,>=1.38.1, but you have grpcio 1.32.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-cloud-storage<2.0.0dev,>=1.26.0, but you have google-cloud-storage 2.1.0 which is incompatible.\r\n",
      "flax 0.5.2 requires rich~=11.1, but you have rich 12.4.4 which is incompatible.\r\n",
      "flax 0.5.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.12.0 which is incompatible.\r\n",
      "featuretools 1.10.0 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\r\n",
      "cmdstanpy 1.0.3 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\r\n",
      "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "black 22.3.0 requires typing-extensions>=3.10.0.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "astroid 2.11.6 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "apache-beam 2.39.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "apache-beam 2.39.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\r\n",
      "aioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\r\n",
      "aiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.20 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed absl-py-0.15.0 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 six-1.15.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.10.0.2 wrapt-1.12.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fe2aec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:04.389597Z",
     "iopub.status.busy": "2022-07-24T12:21:04.389256Z",
     "iopub.status.idle": "2022-07-24T12:21:06.839704Z",
     "shell.execute_reply": "2022-07-24T12:21:06.838753Z"
    },
    "papermill": {
     "duration": 2.4712,
     "end_time": "2022-07-24T12:21:06.842360",
     "exception": false,
     "start_time": "2022-07-24T12:21:04.371160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 12:21:04.498042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend  as K\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab7f7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:06.873777Z",
     "iopub.status.busy": "2022-07-24T12:21:06.873294Z",
     "iopub.status.idle": "2022-07-24T12:21:06.879926Z",
     "shell.execute_reply": "2022-07-24T12:21:06.878764Z"
    },
    "papermill": {
     "duration": 0.024596,
     "end_time": "2022-07-24T12:21:06.882174",
     "exception": false,
     "start_time": "2022-07-24T12:21:06.857578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "IMGS_DIR = \"../input/landcoverai/images/\"\n",
    "MASKS_DIR = \"../input/landcoverai/masks/\"\n",
    "OUTPUT_DIR = \"/kaggle/input/d/revanthvenkateswar/landcoverai/output/\"\n",
    "\n",
    "TARGET_SIZE = 256\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 15\n",
    "epochs = 15\n",
    "train_percent = 0.6\n",
    "val_percent = 0.2\n",
    "seed = 47\n",
    "\n",
    "# 0 is background, 1 is building, 2 is woodland, 3 is water, 4 is road\n",
    "class_weights = {0: 1/(1-(1.85+72.02+13.15+3.5)/216.27), 1: 1/(1.85/216.27), 2: 1/(72.02/216.27), 3: 1/(13.15/216.27), 4: 1/(3.5/216.27)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be51781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:06.913242Z",
     "iopub.status.busy": "2022-07-24T12:21:06.912988Z",
     "iopub.status.idle": "2022-07-24T12:21:06.918640Z",
     "shell.execute_reply": "2022-07-24T12:21:06.917841Z"
    },
    "papermill": {
     "duration": 0.023444,
     "end_time": "2022-07-24T12:21:06.920606",
     "exception": false,
     "start_time": "2022-07-24T12:21:06.897162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# img_paths = glob(os.path.join(IMGS_DIR, \"*.tif\"))\n",
    "# mask_paths = glob(os.path.join(MASKS_DIR, \"*.tif\"))\n",
    "\n",
    "# img_paths.sort()\n",
    "# mask_paths.sort()\n",
    "\n",
    "# if not os.path.exists(OUTPUT_DIR + \"images/\"):\n",
    "#     os.makedirs(OUTPUT_DIR + \"images/\")\n",
    "#     os.makedirs(OUTPUT_DIR + \"masks/\")\n",
    "\n",
    "# for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n",
    "#     img_filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "#     mask_filename = os.path.splitext(os.path.basename(mask_path))[0]\n",
    "#     img = cv2.imread(img_path)\n",
    "#     mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#     assert img_filename == mask_filename and img.shape[:2] == mask.shape[:2]\n",
    "\n",
    "#     k = 0\n",
    "#     for y in range(0, img.shape[0], TARGET_SIZE):\n",
    "#         for x in range(0, img.shape[1], TARGET_SIZE):\n",
    "#             img_tile = img[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n",
    "#             mask_tile = mask[y:y + TARGET_SIZE, x:x + TARGET_SIZE]\n",
    "\n",
    "#             if img_tile.shape[0] == TARGET_SIZE and img_tile.shape[1] == TARGET_SIZE:\n",
    "#                 out_img_name = \"{}_{}.jpg\".format(img_filename, k)\n",
    "#                 out_mask_name = \"{}_m_{}.png\".format(mask_filename, k)\n",
    "                \n",
    "#                 out_img_path = os.path.join(OUTPUT_DIR+\"images/\", out_img_name)\n",
    "#                 cv2.imwrite(out_img_path, img_tile)\n",
    "#                 out_mask_path = os.path.join(OUTPUT_DIR+\"masks/\", out_mask_name)\n",
    "#                 cv2.imwrite(out_mask_path, mask_tile)\n",
    "\n",
    "#             k += 1\n",
    "\n",
    "#     print(\"Processed {} {}/{}\".format(img_filename, i + 1, len(img_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd433c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:06.951102Z",
     "iopub.status.busy": "2022-07-24T12:21:06.950821Z",
     "iopub.status.idle": "2022-07-24T12:21:06.964672Z",
     "shell.execute_reply": "2022-07-24T12:21:06.963806Z"
    },
    "papermill": {
     "duration": 0.031358,
     "end_time": "2022-07-24T12:21:06.966601",
     "exception": false,
     "start_time": "2022-07-24T12:21:06.935243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    image_paths = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    mask_paths = sorted(glob(os.path.join(path, \"masks/*\")))\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "def load_image_and_mask(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image.set_shape([TARGET_SIZE, TARGET_SIZE, 3])\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # # If we subtract 1 from mask,\n",
    "    # # we ignore background in the one hot encoding \n",
    "    # # as tf.one_hot will convert -1 to [0, 0, 0, 0]\n",
    "    # # and 0 as [1, 0, 0, 0]\n",
    "\n",
    "    # mask = mask - 1 \n",
    "    mask = tf.one_hot(mask, depth=NUM_CLASSES)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
    "    mask = tf.squeeze(mask)\n",
    "    mask.set_shape([TARGET_SIZE, TARGET_SIZE, NUM_CLASSES])\n",
    "    return image, mask\n",
    "\n",
    "def create_dataset(image_paths, mask_paths):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths), seed=seed)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(load_image_and_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def test_train_val_split(full_dataset, size, train_percent=0.6, val_percent=0.2, batch_size=8):\n",
    "    train_dataset = full_dataset.take(int(train_percent*size))\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    test_dataset = full_dataset.skip(int(train_percent*size))\n",
    "\n",
    "    val_dataset = test_dataset.take(int(val_percent*size))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.skip(int(val_percent*size))\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a30c47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:07.005645Z",
     "iopub.status.busy": "2022-07-24T12:21:07.005400Z",
     "iopub.status.idle": "2022-07-24T12:21:10.519191Z",
     "shell.execute_reply": "2022-07-24T12:21:10.518035Z"
    },
    "papermill": {
     "duration": 3.533389,
     "end_time": "2022-07-24T12:21:10.523015",
     "exception": false,
     "start_time": "2022-07-24T12:21:06.989626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 12:21:08.648942: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-24 12:21:08.650143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-24 12:21:08.717258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.717960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-07-24 12:21:08.718027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-24 12:21:08.771747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-24 12:21:08.771835: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-24 12:21:08.792513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-24 12:21:08.800567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-24 12:21:08.831343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-24 12:21:08.853678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-24 12:21:08.856413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-24 12:21:08.856583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.857355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.857979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-24 12:21:08.858466: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-24 12:21:08.858640: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-24 12:21:08.858793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.859390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2022-07-24 12:21:08.859429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-24 12:21:08.859450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-24 12:21:08.859465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-24 12:21:08.859480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-24 12:21:08.859494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-24 12:21:08.859508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-07-24 12:21:08.859523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-24 12:21:08.859538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-24 12:21:08.859605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.860247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:08.860778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-07-24 12:21:08.860829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-24 12:21:09.502543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-24 12:21:09.502592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-07-24 12:21:09.502605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-07-24 12:21:09.502968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:09.504100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:09.505152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-24 12:21:09.506125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "image_paths, mask_paths = load_data(OUTPUT_DIR)\n",
    "dataset = create_dataset(image_paths, mask_paths)\n",
    "train, val, test = test_train_val_split(dataset, len(image_paths), train_percent, val_percent, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263d96ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:10.576793Z",
     "iopub.status.busy": "2022-07-24T12:21:10.576350Z",
     "iopub.status.idle": "2022-07-24T12:21:10.608334Z",
     "shell.execute_reply": "2022-07-24T12:21:10.607165Z"
    },
    "papermill": {
     "duration": 0.061603,
     "end_time": "2022-07-24T12:21:10.610902",
     "exception": false,
     "start_time": "2022-07-24T12:21:10.549299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_bn(x, filters, kernel_size=3, strides=1):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding='same',\n",
    "                               use_bias=True)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dilated_conv_bn(x, filters, kernel_size=3, rate=1):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=kernel_size,\n",
    "                               padding='same',\n",
    "                               use_bias=True,\n",
    "                               dilation_rate=(rate,rate))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def dilated_spatial_pyramidal_pooling_conv(x, filters, kernel_size=3):\n",
    "    x2 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=3,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(2,2))(x)\n",
    "    x4 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=3,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(4,4))(x)\n",
    "    x8 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                kernel_size=6,\n",
    "                                padding='same',\n",
    "                                use_bias=True,\n",
    "                                dilation_rate=(8,8))(x)\n",
    "    x16 = tf.keras.layers.Conv2D(filters=8,\n",
    "                                 kernel_size=9,\n",
    "                                 padding='same',\n",
    "                                 use_bias=True,\n",
    "                                 dilation_rate=(8,8))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x, x2, x4, x8, x16])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(filters=filters,\n",
    "                               kernel_size=1,\n",
    "                               padding='same',\n",
    "                               use_bias=True)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def model(x):\n",
    "    # Encoder\n",
    "    x = conv_bn(x, filters=16)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x1 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=2)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x2 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=4)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x4 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=8)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x8 = dilated_spatial_pyramidal_pooling_conv(x, filters=16)\n",
    "    x = dilated_conv_bn(x, filters=64, rate=16)\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = conv_bn(x, filters=32)\n",
    "\n",
    "    # Decoder\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x8, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x4, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x2, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "    x = tf.keras.layers.Concatenate(axis=3)([x1, x])\n",
    "    x = conv_bn(x, filters=32)\n",
    "\n",
    "    # Number of filters = number of classes\n",
    "    x = tf.keras.layers.Conv2D(filters=NUM_CLASSES, kernel_size=1, strides=1, activation='softmax')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7949f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:10.664642Z",
     "iopub.status.busy": "2022-07-24T12:21:10.664352Z",
     "iopub.status.idle": "2022-07-24T12:21:10.734577Z",
     "shell.execute_reply": "2022-07-24T12:21:10.733724Z"
    },
    "papermill": {
     "duration": 0.100043,
     "end_time": "2022-07-24T12:21:10.736560",
     "exception": false,
     "start_time": "2022-07-24T12:21:10.636517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file is taken \n",
    "# from https://github.com/mlyg/unified-focal-loss/blob/main/loss_functions.py\n",
    "# Edited to make it compatible with multi-class segmentation\n",
    "\n",
    "# Helper function to enable loss function to be flexibly used for \n",
    "# both 2D or 3D image segmentation - source: https://github.com/frankkramer-lab/MIScnn\n",
    "def identify_axis(shape):\n",
    "    # Three dimensional\n",
    "    if len(shape) == 5 : return [1,2,3]\n",
    "    # Two dimensional\n",
    "    elif len(shape) == 4 : return [1,2]\n",
    "    # Exception - Unknown\n",
    "    else : raise ValueError('Metric: Shape of tensor is neither 2D or 3D.')\n",
    "\n",
    "################################\n",
    "#       Dice coefficient       #\n",
    "################################\n",
    "def dice_coefficient(delta = 0.5, smooth = 0.000001):\n",
    "    \"\"\"The Dice similarity coefficient, also known as the Sørensen–Dice index or simply Dice coefficient, is a statistical tool which measures the similarity between two sets of data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.5\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)   \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        dice = K.mean(dice_class)\n",
    "\n",
    "        return dice\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#           Dice loss          #\n",
    "################################\n",
    "def dice_loss(delta = 0.5, smooth = 0.000001):\n",
    "    \"\"\"Dice loss originates from Sørensen–Dice coefficient, which is a statistic developed in 1940s to gauge the similarity between two samples.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.5\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)\n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        # Calculate Dice score\n",
    "        dice_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        dice_loss = K.mean(1-dice_class)\n",
    "\n",
    "        return dice_loss\n",
    "        \n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#         Tversky loss         #\n",
    "################################\n",
    "def tversky_loss(delta = 0.7, smooth = 0.000001):\n",
    "    \"\"\"Tversky loss function for image segmentation using 3D fully convolutional deep networks\n",
    "\tLink: https://arxiv.org/abs/1706.05721\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    smooth : float, optional\n",
    "        smoothing constant to prevent division by zero errors, by default 0.000001\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)   \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        tversky_loss = K.mean(1-tversky_class)\n",
    "\n",
    "        return tversky_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#          Combo loss          #\n",
    "################################\n",
    "def combo_loss(alpha=0.5,beta=0.5):\n",
    "    \"\"\"Combo Loss: Handling Input and Output Imbalance in Multi-Organ Segmentation\n",
    "    Link: https://arxiv.org/abs/1805.02798\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional\n",
    "        controls weighting of dice and cross-entropy loss., by default 0.5\n",
    "    beta : float, optional\n",
    "        beta > 0.5 penalises false negatives more than false positives., by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        dice = dice_coefficient()(y_true, y_pred)\n",
    "        # axis = identify_axis(y_true.get_shape())\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        if beta is not None:\n",
    "            beta_weight = np.array([beta, 1-beta])\n",
    "            cross_entropy = beta_weight * cross_entropy\n",
    "        # sum over classes\n",
    "        cross_entropy = K.mean(K.sum(cross_entropy, axis=[-1]))\n",
    "        if alpha is not None:\n",
    "            combo_loss = (alpha * cross_entropy) - ((1 - alpha) * dice)\n",
    "        else:\n",
    "            combo_loss = cross_entropy - dice\n",
    "        return combo_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#      Focal Tversky loss      #\n",
    "################################\n",
    "def focal_tversky_loss(delta=0.7, gamma=0.75, smooth=0.000001):\n",
    "    \"\"\"A Novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation\n",
    "    Link: https://arxiv.org/abs/1810.07842\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon) \n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        tversky_class = (tp + smooth)/(tp + delta*fn + (1-delta)*fp + smooth)\n",
    "        # Average class scores\n",
    "        focal_tversky_loss = K.mean(K.pow((1-tversky_class), gamma))\n",
    "\t\n",
    "        return focal_tversky_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#          Focal loss          #\n",
    "################################\n",
    "def focal_loss(alpha=None, gamma_f=2.):\n",
    "    \"\"\"Focal loss is used to address the issue of the class imbalance problem. A modulation term applied to the Cross-Entropy loss function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, optional\n",
    "        controls relative weight of false positives and false negatives. alpha > 0.5 penalises false negatives more than false positives, by default None\n",
    "    gamma_f : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 2.\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # axis = identify_axis(y_true.get_shape())\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        if alpha is not None:\n",
    "            alpha_weight = np.array(alpha, dtype=np.float32)\n",
    "            focal_loss = alpha_weight * K.pow(1 - y_pred, gamma_f) * cross_entropy\n",
    "        else:\n",
    "            focal_loss = K.pow(1 - y_pred, gamma_f) * cross_entropy\n",
    "\n",
    "        focal_loss = K.mean(K.sum(focal_loss, axis=[-1]))\n",
    "        return focal_loss\n",
    "        \n",
    "    return loss_function\n",
    "\n",
    "################################\n",
    "#     Symmetric Focal loss     #\n",
    "################################\n",
    "def symmetric_focal_loss(delta=0.7, gamma=2.):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        Focal Tversky loss' focal parameter controls degree of down-weighting of easy examples, by default 2.0\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "\n",
    "        # axis = identify_axis(y_true.get_shape())  \n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        #calculate losses separately for each class\n",
    "        background_ce = K.pow(1 - y_pred[:,:,:,0], gamma) * cross_entropy[:,:,:,0]\n",
    "        background_ce =  (1 - delta) * background_ce\n",
    "\n",
    "        # This section is modified for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_ce = [background_ce]\n",
    "        \n",
    "        for i in range(1, numClasses):\n",
    "            class_ce = cross_entropy[:,:,:,i]\n",
    "            class_ce = delta * class_ce\n",
    "            list_of_class_ce.append(class_ce)\n",
    "\n",
    "        loss = K.mean(K.sum(tf.stack(list_of_class_ce, axis=-1), axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "#################################\n",
    "# Symmetric Focal Tversky loss  #\n",
    "#################################\n",
    "def symmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for multi-class segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon)/(tp + delta*fn + (1-delta)*fp + epsilon)\n",
    "\n",
    "        #calculate losses separately for each class, enhancing both classes\n",
    "        background_dice = (1-dice_class[:,0]) * K.pow(1-dice_class[:,0], -gamma)\n",
    "\n",
    "        # modify this section below for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_dice = [background_dice]\n",
    "        for i in range(1, numClasses):\n",
    "            class_dice = (1-dice_class[:,i]) * K.pow(1-dice_class[:,i], -gamma)\n",
    "            list_of_class_dice.append(class_dice)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack(list_of_class_dice, axis=-1))\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "################################\n",
    "#     Asymmetric Focal loss    #\n",
    "################################\n",
    "def asymmetric_focal_loss(delta=0.7, gamma=2.):\n",
    "    \"\"\"For Imbalanced datasets (multi-class)\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        Focal Tversky loss' focal parameter controls degree of down-weighting of easy examples, by default 2.0\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        axis = identify_axis(y_true.get_shape())  \n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        #calculate losses separately for each class, only suppressing background class\n",
    "        background_ce = K.pow(1 - y_pred[:,:,:,0], gamma) * cross_entropy[:,:,:,0]\n",
    "        background_ce =  (1 - delta) * background_ce\n",
    "\n",
    "        # This section is modified for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_ce = [background_ce]\n",
    "\n",
    "        for i in range(1, numClasses):\n",
    "            class_ce = cross_entropy[:,:,:,i]\n",
    "            class_ce = delta * class_ce\n",
    "            list_of_class_ce.append(class_ce)\n",
    "\n",
    "        loss = K.mean(K.sum(tf.stack(list_of_class_ce, axis=-1), axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "#################################\n",
    "# Asymmetric Focal Tversky loss #\n",
    "#################################\n",
    "def asymmetric_focal_tversky_loss(delta=0.7, gamma=0.75):\n",
    "    \"\"\"This is the implementation for multi-class segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    \"\"\"\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Clip values to prevent division by zero error\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        axis = identify_axis(y_true.get_shape())\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = K.sum(y_true * y_pred, axis=axis)\n",
    "        fn = K.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = K.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + epsilon)/(tp + delta*fn + (1-delta)*fp + epsilon)\n",
    "\n",
    "        #calculate losses separately for each class, enhancing both classes\n",
    "        background_dice = (1-dice_class[:,0])\n",
    "\n",
    "        # modify this section below for multiclass segmentation\n",
    "        numClasses = K.int_shape(y_pred)[-1]\n",
    "        list_of_class_dice = [background_dice]\n",
    "        for i in range(1, numClasses):\n",
    "            class_dice = (1-dice_class[:,i]) * K.pow(1-dice_class[:,i], -gamma)\n",
    "            list_of_class_dice.append(class_dice)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = K.mean(tf.stack(list_of_class_dice, axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "\n",
    "###########################################\n",
    "#      Symmetric Unified Focal loss       #\n",
    "###########################################\n",
    "def sym_unified_focal_loss(weight=0.5, delta=0.6, gamma=0.5):\n",
    "    \"\"\"The Unified Focal loss is a new compound loss function that unifies Dice-based and cross entropy-based loss functions into a single framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight : float, optional\n",
    "        represents lambda parameter and controls weight given to symmetric Focal Tversky loss and symmetric Focal loss, by default 0.5\n",
    "    delta : float, optional\n",
    "        controls weight given to each class, by default 0.6\n",
    "    gamma : float, optional\n",
    "        focal parameter controls the degree of background suppression and foreground enhancement, by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        symmetric_ftl = symmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        symmetric_fl = symmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        if weight is not None:\n",
    "            return (weight * symmetric_ftl) + ((1-weight) * symmetric_fl)  \n",
    "        else:\n",
    "            return symmetric_ftl + symmetric_fl\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "###########################################\n",
    "#      Asymmetric Unified Focal loss      #\n",
    "###########################################\n",
    "def asym_unified_focal_loss(weight=0.5, delta=0.6, gamma=0.5):\n",
    "    \"\"\"The Unified Focal loss is a new compound loss function that unifies Dice-based and cross entropy-based loss functions into a single framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight : float, optional\n",
    "        represents lambda parameter and controls weight given to asymmetric Focal Tversky loss and asymmetric Focal loss, by default 0.5\n",
    "    delta : float, optional\n",
    "        controls weight given to each class, by default 0.6\n",
    "    gamma : float, optional\n",
    "        focal parameter controls the degree of background suppression and foreground enhancement, by default 0.5\n",
    "    \"\"\"\n",
    "    def loss_function(y_true,y_pred):\n",
    "        asymmetric_ftl = asymmetric_focal_tversky_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        asymmetric_fl = asymmetric_focal_loss(delta=delta, gamma=gamma)(y_true,y_pred)\n",
    "        if weight is not None:\n",
    "            return (weight * asymmetric_ftl) + ((1-weight) * asymmetric_fl)  \n",
    "        else:\n",
    "            return asymmetric_ftl + asymmetric_fl\n",
    "\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97e8b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:10.768536Z",
     "iopub.status.busy": "2022-07-24T12:21:10.767830Z",
     "iopub.status.idle": "2022-07-24T12:21:10.775305Z",
     "shell.execute_reply": "2022-07-24T12:21:10.774306Z"
    },
    "papermill": {
     "duration": 0.025764,
     "end_time": "2022-07-24T12:21:10.777571",
     "exception": false,
     "start_time": "2022-07-24T12:21:10.751807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#         OneHot MeanIoU       #\n",
    "################################\n",
    "class OneHotMeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    '''\n",
    "    Custom metric to calculate OneHotMeanIoU\n",
    "    as the keras version is not available in tf 2.6\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        name=None,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        super(OneHotMeanIoU, self).__init__(\n",
    "            num_classes=num_classes,\n",
    "            name=name,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"Accumulates the confusion matrix statistics.\n",
    "        Args:\n",
    "          y_true: The ground truth values.\n",
    "          y_pred: The predicted values.\n",
    "          sample_weight: Optional weighting of each example. Defaults to 1. Can be a\n",
    "            `Tensor` whose rank is either 0, or the same rank as `y_true`, and must\n",
    "            be broadcastable to `y_true`.\n",
    "        Returns:\n",
    "          Update op.\n",
    "        \"\"\"\n",
    "        # Select max hot-encoding channels to convert into all-class format\n",
    "        y_true = tf.argmax(y_true, axis=-1, output_type=tf.int32)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1, output_type=tf.int32)\n",
    "        \n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53764021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:10.809947Z",
     "iopub.status.busy": "2022-07-24T12:21:10.809674Z",
     "iopub.status.idle": "2022-07-24T12:21:11.366114Z",
     "shell.execute_reply": "2022-07-24T12:21:11.365154Z"
    },
    "papermill": {
     "duration": 0.575321,
     "end_time": "2022-07-24T12:21:11.368482",
     "exception": false,
     "start_time": "2022-07-24T12:21:10.793161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input = tf.keras.layers.Input(shape=[TARGET_SIZE, TARGET_SIZE, 3])\n",
    "output = model(input)\n",
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3115a42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:11.401109Z",
     "iopub.status.busy": "2022-07-24T12:21:11.400307Z",
     "iopub.status.idle": "2022-07-24T12:21:11.463516Z",
     "shell.execute_reply": "2022-07-24T12:21:11.462662Z"
    },
    "papermill": {
     "duration": 0.085344,
     "end_time": "2022-07-24T12:21:11.469574",
     "exception": false,
     "start_time": "2022-07-24T12:21:11.384230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 4640        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 64) 18496       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 256, 32) 18464       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 32) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 256, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 64) 18496       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 32) 18464       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 32) 128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 256, 256, 32) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 18496       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256, 256, 64) 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 256, 256, 64) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 32) 18464       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256, 256, 32) 128         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256, 256, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 64) 18496       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 256, 64) 256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256, 256, 64) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 32) 18464       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 8)  2312        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 8)  2312        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 8)  9224        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 8)  20744       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256, 256, 32) 128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           activation_10[0][0]              \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 256, 256, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256, 256, 64) 256         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 32) 9248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 16) 1040        batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 32) 128         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 8)  2312        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 8)  2312        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 8)  9224        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 8)  20744       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256, 256, 16) 0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 64) 0           activation_7[0][0]               \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 48) 0           activation_11[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256, 256, 64) 256         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 32) 13856       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 16) 1040        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 32) 128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 8)  2312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 256, 256, 8)  2312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 256, 256, 8)  9224        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 8)  20744       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 256, 16) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 64) 0           activation_4[0][0]               \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 256, 48) 0           activation_8[0][0]               \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 64) 256         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 256, 256, 32) 13856       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 16) 1040        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 32) 128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 8)  2312        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 8)  2312        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 8)  9224        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 8)  20744       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 256, 16) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 256, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 256, 256, 48) 0           activation_5[0][0]               \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 32) 13856       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 16) 1040        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 32) 128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 16) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 256, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 48) 0           activation_2[0][0]               \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 32) 13856       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 32) 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 32) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 256, 5)  165         activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 363,685\n",
      "Trainable params: 361,989\n",
      "Non-trainable params: 1,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "# 0 is background, 1 is building, 2 is woodland, 3 is water, 4 is road\n",
    "model.compile(optimizer='adam', loss=asym_unified_focal_loss(), \n",
    "              metrics=[OneHotMeanIoU(NUM_CLASSES, name='MeanIoU'),\n",
    "                       Precision(name='bgrPcsn', class_id=0),\n",
    "                       Precision(name='bldPcsn', class_id=1),\n",
    "                       Precision(name='wldPcsn', class_id=2),\n",
    "                       Precision(name='wtrPcsn', class_id=3),\n",
    "                       Precision(name='roadPcsn', class_id=4),\n",
    "                       Recall(name='bgrRcl', class_id=0),\n",
    "                       Recall(name='bldRcl', class_id=1),\n",
    "                       Recall(name='wldRcl', class_id=2),\n",
    "                       Recall(name='wtrRcl', class_id=3),\n",
    "                       Recall(name='roadRcl', class_id=4)\n",
    "                      ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acf255c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T12:21:11.502223Z",
     "iopub.status.busy": "2022-07-24T12:21:11.501755Z",
     "iopub.status.idle": "2022-07-24T19:00:22.581460Z",
     "shell.execute_reply": "2022-07-24T19:00:22.580309Z"
    },
    "papermill": {
     "duration": 23952.973433,
     "end_time": "2022-07-24T19:00:24.458728",
     "exception": false,
     "start_time": "2022-07-24T12:21:11.485295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 12:21:11.521184: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-24 12:21:11.522553: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000150000 Hz\n",
      "2022-07-24 12:21:18.744370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-24 12:21:24.922184: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-24 12:21:25.775522: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1765/1765 [==============================] - 1702s 955ms/step - loss: 0.5579 - MeanIoU: 0.3741 - bgrPcsn: 0.8632 - bldPcsn: 0.4754 - wldPcsn: 0.7593 - wtrPcsn: 0.5451 - roadPcsn: 0.3689 - bgrRcl: 0.7517 - bldRcl: 0.1222 - wldRcl: 0.8079 - wtrRcl: 0.2918 - roadRcl: 0.1370 - val_loss: 0.4863 - val_MeanIoU: 0.5087 - val_bgrPcsn: 0.9033 - val_bldPcsn: 0.6283 - val_wldPcsn: 0.8611 - val_wtrPcsn: 0.5857 - val_roadPcsn: 0.4984 - val_bgrRcl: 0.8545 - val_bldRcl: 0.3566 - val_wldRcl: 0.8947 - val_wtrRcl: 0.6922 - val_roadRcl: 0.2404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 12:49:37.178994: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "1765/1765 [==============================] - 1592s 902ms/step - loss: 0.4854 - MeanIoU: 0.5433 - bgrPcsn: 0.9064 - bldPcsn: 0.6397 - wldPcsn: 0.8413 - wtrPcsn: 0.7345 - roadPcsn: 0.4996 - bgrRcl: 0.8560 - bldRcl: 0.4323 - wldRcl: 0.8949 - wtrRcl: 0.6723 - roadRcl: 0.3290 - val_loss: 0.4952 - val_MeanIoU: 0.5040 - val_bgrPcsn: 0.9526 - val_bldPcsn: 0.2157 - val_wldPcsn: 0.8628 - val_wtrPcsn: 0.7838 - val_roadPcsn: 0.1990 - val_bgrRcl: 0.7453 - val_bldRcl: 0.8728 - val_wldRcl: 0.9190 - val_wtrRcl: 0.8131 - val_roadRcl: 0.4306\n",
      "Epoch 3/15\n",
      "1765/1765 [==============================] - 1585s 898ms/step - loss: 0.4658 - MeanIoU: 0.6028 - bgrPcsn: 0.9247 - bldPcsn: 0.6782 - wldPcsn: 0.8625 - wtrPcsn: 0.7925 - roadPcsn: 0.5372 - bgrRcl: 0.8754 - bldRcl: 0.5792 - wldRcl: 0.9156 - wtrRcl: 0.7607 - roadRcl: 0.4059 - val_loss: 0.4787 - val_MeanIoU: 0.5617 - val_bgrPcsn: 0.9433 - val_bldPcsn: 0.8354 - val_wldPcsn: 0.8254 - val_wtrPcsn: 0.5465 - val_roadPcsn: 0.7021 - val_bgrRcl: 0.8009 - val_bldRcl: 0.5082 - val_wldRcl: 0.9438 - val_wtrRcl: 0.8635 - val_roadRcl: 0.3049\n",
      "Epoch 4/15\n",
      "1765/1765 [==============================] - 1583s 897ms/step - loss: 0.4537 - MeanIoU: 0.6359 - bgrPcsn: 0.9350 - bldPcsn: 0.7006 - wldPcsn: 0.8749 - wtrPcsn: 0.8293 - roadPcsn: 0.5745 - bgrRcl: 0.8897 - bldRcl: 0.6195 - wldRcl: 0.9266 - wtrRcl: 0.8021 - roadRcl: 0.4607 - val_loss: 0.5044 - val_MeanIoU: 0.5188 - val_bgrPcsn: 0.9450 - val_bldPcsn: 0.4798 - val_wldPcsn: 0.7309 - val_wtrPcsn: 0.7059 - val_roadPcsn: 0.7030 - val_bgrRcl: 0.7546 - val_bldRcl: 0.6490 - val_wldRcl: 0.9741 - val_wtrRcl: 0.7108 - val_roadRcl: 0.2449\n",
      "Epoch 5/15\n",
      "1765/1765 [==============================] - 1580s 895ms/step - loss: 0.4481 - MeanIoU: 0.6520 - bgrPcsn: 0.9377 - bldPcsn: 0.7116 - wldPcsn: 0.8833 - wtrPcsn: 0.8482 - roadPcsn: 0.5943 - bgrRcl: 0.8975 - bldRcl: 0.6490 - wldRcl: 0.9306 - wtrRcl: 0.8121 - roadRcl: 0.4814 - val_loss: 0.4645 - val_MeanIoU: 0.5853 - val_bgrPcsn: 0.9303 - val_bldPcsn: 0.7222 - val_wldPcsn: 0.8472 - val_wtrPcsn: 0.8659 - val_roadPcsn: 0.3482 - val_bgrRcl: 0.8483 - val_bldRcl: 0.6108 - val_wldRcl: 0.9525 - val_wtrRcl: 0.5895 - val_roadRcl: 0.5632\n",
      "Epoch 6/15\n",
      "1765/1765 [==============================] - 1573s 891ms/step - loss: 0.4454 - MeanIoU: 0.6636 - bgrPcsn: 0.9398 - bldPcsn: 0.7192 - wldPcsn: 0.8840 - wtrPcsn: 0.8647 - roadPcsn: 0.6167 - bgrRcl: 0.9014 - bldRcl: 0.6607 - wldRcl: 0.9320 - wtrRcl: 0.8244 - roadRcl: 0.5010 - val_loss: 0.4605 - val_MeanIoU: 0.6034 - val_bgrPcsn: 0.9350 - val_bldPcsn: 0.7787 - val_wldPcsn: 0.8918 - val_wtrPcsn: 0.5471 - val_roadPcsn: 0.6965 - val_bgrRcl: 0.8508 - val_bldRcl: 0.6407 - val_wldRcl: 0.9220 - val_wtrRcl: 0.8344 - val_roadRcl: 0.3993\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 7/15\n",
      "1765/1765 [==============================] - 1576s 893ms/step - loss: 0.4321 - MeanIoU: 0.7020 - bgrPcsn: 0.9508 - bldPcsn: 0.7458 - wldPcsn: 0.8921 - wtrPcsn: 0.9157 - roadPcsn: 0.6361 - bgrRcl: 0.9137 - bldRcl: 0.7224 - wldRcl: 0.9425 - wtrRcl: 0.8713 - roadRcl: 0.5343 - val_loss: 0.4241 - val_MeanIoU: 0.7260 - val_bgrPcsn: 0.9530 - val_bldPcsn: 0.8021 - val_wldPcsn: 0.9058 - val_wtrPcsn: 0.9050 - val_roadPcsn: 0.6936 - val_bgrRcl: 0.9240 - val_bldRcl: 0.7198 - val_wldRcl: 0.9421 - val_wtrRcl: 0.9040 - val_roadRcl: 0.5594\n",
      "Epoch 8/15\n",
      "1765/1765 [==============================] - 1576s 893ms/step - loss: 0.4277 - MeanIoU: 0.7117 - bgrPcsn: 0.9533 - bldPcsn: 0.7557 - wldPcsn: 0.8983 - wtrPcsn: 0.9218 - roadPcsn: 0.6434 - bgrRcl: 0.9193 - bldRcl: 0.7244 - wldRcl: 0.9453 - wtrRcl: 0.8894 - roadRcl: 0.5382 - val_loss: 0.4215 - val_MeanIoU: 0.7310 - val_bgrPcsn: 0.9605 - val_bldPcsn: 0.7620 - val_wldPcsn: 0.8978 - val_wtrPcsn: 0.9375 - val_roadPcsn: 0.6372 - val_bgrRcl: 0.9188 - val_bldRcl: 0.7529 - val_wldRcl: 0.9517 - val_wtrRcl: 0.9164 - val_roadRcl: 0.5918\n",
      "Epoch 9/15\n",
      "1765/1765 [==============================] - 1575s 892ms/step - loss: 0.4267 - MeanIoU: 0.7149 - bgrPcsn: 0.9544 - bldPcsn: 0.7581 - wldPcsn: 0.9000 - wtrPcsn: 0.9224 - roadPcsn: 0.6475 - bgrRcl: 0.9203 - bldRcl: 0.7353 - wldRcl: 0.9465 - wtrRcl: 0.8909 - roadRcl: 0.5394 - val_loss: 0.4209 - val_MeanIoU: 0.7345 - val_bgrPcsn: 0.9599 - val_bldPcsn: 0.7936 - val_wldPcsn: 0.8992 - val_wtrPcsn: 0.9293 - val_roadPcsn: 0.6398 - val_bgrRcl: 0.9198 - val_bldRcl: 0.7571 - val_wldRcl: 0.9509 - val_wtrRcl: 0.9117 - val_roadRcl: 0.5967\n",
      "Epoch 10/15\n",
      "1765/1765 [==============================] - 1578s 894ms/step - loss: 0.4260 - MeanIoU: 0.7200 - bgrPcsn: 0.9548 - bldPcsn: 0.7594 - wldPcsn: 0.8996 - wtrPcsn: 0.9274 - roadPcsn: 0.6524 - bgrRcl: 0.9205 - bldRcl: 0.7380 - wldRcl: 0.9459 - wtrRcl: 0.8973 - roadRcl: 0.5586 - val_loss: 0.4203 - val_MeanIoU: 0.7358 - val_bgrPcsn: 0.9569 - val_bldPcsn: 0.7422 - val_wldPcsn: 0.9085 - val_wtrPcsn: 0.9377 - val_roadPcsn: 0.6537 - val_bgrRcl: 0.9262 - val_bldRcl: 0.7844 - val_wldRcl: 0.9448 - val_wtrRcl: 0.9214 - val_roadRcl: 0.5908\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 11/15\n",
      "1765/1765 [==============================] - 1581s 896ms/step - loss: 0.4243 - MeanIoU: 0.7254 - bgrPcsn: 0.9551 - bldPcsn: 0.7548 - wldPcsn: 0.9042 - wtrPcsn: 0.9353 - roadPcsn: 0.6551 - bgrRcl: 0.9234 - bldRcl: 0.7462 - wldRcl: 0.9470 - wtrRcl: 0.9018 - roadRcl: 0.5671 - val_loss: 0.4183 - val_MeanIoU: 0.7368 - val_bgrPcsn: 0.9604 - val_bldPcsn: 0.7722 - val_wldPcsn: 0.9073 - val_wtrPcsn: 0.9326 - val_roadPcsn: 0.6576 - val_bgrRcl: 0.9269 - val_bldRcl: 0.7588 - val_wldRcl: 0.9503 - val_wtrRcl: 0.9182 - val_roadRcl: 0.5853\n",
      "Epoch 12/15\n",
      "1765/1765 [==============================] - 1581s 896ms/step - loss: 0.4246 - MeanIoU: 0.7239 - bgrPcsn: 0.9558 - bldPcsn: 0.7655 - wldPcsn: 0.8993 - wtrPcsn: 0.9360 - roadPcsn: 0.6549 - bgrRcl: 0.9209 - bldRcl: 0.7326 - wldRcl: 0.9473 - wtrRcl: 0.9028 - roadRcl: 0.5645 - val_loss: 0.4183 - val_MeanIoU: 0.7439 - val_bgrPcsn: 0.9590 - val_bldPcsn: 0.7829 - val_wldPcsn: 0.9101 - val_wtrPcsn: 0.9400 - val_roadPcsn: 0.6746 - val_bgrRcl: 0.9279 - val_bldRcl: 0.7732 - val_wldRcl: 0.9503 - val_wtrRcl: 0.9194 - val_roadRcl: 0.5867\n",
      "Epoch 13/15\n",
      "1765/1765 [==============================] - 1580s 895ms/step - loss: 0.4239 - MeanIoU: 0.7239 - bgrPcsn: 0.9562 - bldPcsn: 0.7699 - wldPcsn: 0.8998 - wtrPcsn: 0.9335 - roadPcsn: 0.6546 - bgrRcl: 0.9222 - bldRcl: 0.7411 - wldRcl: 0.9477 - wtrRcl: 0.8996 - roadRcl: 0.5555 - val_loss: 0.4188 - val_MeanIoU: 0.7418 - val_bgrPcsn: 0.9607 - val_bldPcsn: 0.7776 - val_wldPcsn: 0.8999 - val_wtrPcsn: 0.9405 - val_roadPcsn: 0.6871 - val_bgrRcl: 0.9242 - val_bldRcl: 0.7768 - val_wldRcl: 0.9524 - val_wtrRcl: 0.9152 - val_roadRcl: 0.5818\n",
      "Epoch 14/15\n",
      "1765/1765 [==============================] - 1580s 895ms/step - loss: 0.4232 - MeanIoU: 0.7273 - bgrPcsn: 0.9564 - bldPcsn: 0.7712 - wldPcsn: 0.9003 - wtrPcsn: 0.9322 - roadPcsn: 0.6653 - bgrRcl: 0.9235 - bldRcl: 0.7531 - wldRcl: 0.9474 - wtrRcl: 0.8975 - roadRcl: 0.5631 - val_loss: 0.4183 - val_MeanIoU: 0.7400 - val_bgrPcsn: 0.9619 - val_bldPcsn: 0.7681 - val_wldPcsn: 0.9027 - val_wtrPcsn: 0.9412 - val_roadPcsn: 0.6730 - val_bgrRcl: 0.9235 - val_bldRcl: 0.7674 - val_wldRcl: 0.9543 - val_wtrRcl: 0.9228 - val_roadRcl: 0.5807\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 15/15\n",
      "1765/1765 [==============================] - 1578s 894ms/step - loss: 0.4227 - MeanIoU: 0.7293 - bgrPcsn: 0.9570 - bldPcsn: 0.7655 - wldPcsn: 0.9048 - wtrPcsn: 0.9331 - roadPcsn: 0.6627 - bgrRcl: 0.9249 - bldRcl: 0.7504 - wldRcl: 0.9489 - wtrRcl: 0.9027 - roadRcl: 0.5711 - val_loss: 0.4186 - val_MeanIoU: 0.7427 - val_bgrPcsn: 0.9593 - val_bldPcsn: 0.7783 - val_wldPcsn: 0.9093 - val_wtrPcsn: 0.9397 - val_roadPcsn: 0.6765 - val_bgrRcl: 0.9286 - val_bldRcl: 0.7666 - val_wldRcl: 0.9496 - val_wtrRcl: 0.9166 - val_roadRcl: 0.5929\n"
     ]
    }
   ],
   "source": [
    "save_model_path = '/kaggle/working/checkpoint_7'\n",
    "\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=save_model_path, \n",
    "    monitor='val_MeanIoU', \n",
    "    mode='max', \n",
    "    save_best_only=True\n",
    ")\n",
    "cb_earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_MeanIoU',\n",
    "    mode='max',\n",
    "    min_delta=0.001,\n",
    "    patience=4,\n",
    "    verbose=1\n",
    ")\n",
    "cb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_MeanIoU',\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    verbose=1,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "    \n",
    "history = model.fit(train.repeat(), \n",
    "                    steps_per_epoch=int(np.ceil(train_percent*len(image_paths) / float(BATCH_SIZE))),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val.repeat(),\n",
    "                    validation_steps=int(np.ceil(val_percent*len(image_paths) / float(BATCH_SIZE))),\n",
    "                    callbacks=[cp, cb_earlystop, cb_reducelr],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "578652a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T19:00:28.317286Z",
     "iopub.status.busy": "2022-07-24T19:00:28.316926Z",
     "iopub.status.idle": "2022-07-24T19:00:42.020372Z",
     "shell.execute_reply": "2022-07-24T19:00:42.019206Z"
    },
    "papermill": {
     "duration": 15.818322,
     "end_time": "2022-07-24T19:00:42.033460",
     "exception": false,
     "start_time": "2022-07-24T19:00:26.215138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/model_7/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/variables/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/variables/variables.index (deflated 80%)\r\n",
      "  adding: kaggle/working/model_7/variables/variables.data-00000-of-00001 (deflated 9%)\r\n",
      "  adding: kaggle/working/model_7/assets/ (stored 0%)\r\n",
      "  adding: kaggle/working/model_7/saved_model.pb (deflated 92%)\r\n"
     ]
    }
   ],
   "source": [
    "model.save('/kaggle/working/model_7')\n",
    "!zip -r model_7.zip /kaggle/working/model_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3fb4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T19:00:46.176174Z",
     "iopub.status.busy": "2022-07-24T19:00:46.175379Z",
     "iopub.status.idle": "2022-07-24T19:00:46.180321Z",
     "shell.execute_reply": "2022-07-24T19:00:46.179450Z"
    },
    "papermill": {
     "duration": 2.382584,
     "end_time": "2022-07-24T19:00:46.182334",
     "exception": false,
     "start_time": "2022-07-24T19:00:43.799750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('/kaggle/input/model6/model_6/', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bce7f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T19:00:50.072826Z",
     "iopub.status.busy": "2022-07-24T19:00:50.072477Z",
     "iopub.status.idle": "2022-07-24T19:04:27.733571Z",
     "shell.execute_reply": "2022-07-24T19:04:27.732626Z"
    },
    "papermill": {
     "duration": 219.679143,
     "end_time": "2022-07-24T19:04:27.735572",
     "exception": false,
     "start_time": "2022-07-24T19:00:48.056429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589/589 [==============================] - 218s 276ms/step - loss: 0.4174 - MeanIoU: 0.7445 - bgrPcsn: 0.9597 - bldPcsn: 0.7762 - wldPcsn: 0.9054 - wtrPcsn: 0.9392 - roadPcsn: 0.6939 - bgrRcl: 0.9286 - bldRcl: 0.7727 - wldRcl: 0.9482 - wtrRcl: 0.9181 - roadRcl: 0.5962\n",
      "Restored model, accuracy: 74.45%\n"
     ]
    }
   ],
   "source": [
    "loss, acc, *is_anything_else_being_returned = model.evaluate(test, verbose=1, batch_size=BATCH_SIZE)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1210d648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T19:04:31.701038Z",
     "iopub.status.busy": "2022-07-24T19:04:31.700645Z",
     "iopub.status.idle": "2022-07-24T19:04:31.705918Z",
     "shell.execute_reply": "2022-07-24T19:04:31.704920Z"
    },
    "papermill": {
     "duration": 1.812627,
     "end_time": "2022-07-24T19:04:31.707956",
     "exception": false,
     "start_time": "2022-07-24T19:04:29.895329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def display(display_list):\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "\n",
    "#     title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "#     for i in range(len(display_list)):\n",
    "#         plt.subplot(1, len(display_list), i+1)\n",
    "#         plt.title(title[i])\n",
    "#         plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "#         plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# def create_mask(mask):\n",
    "#     condensed_mask = tf.math.argmax(mask, axis=-1)\n",
    "#     condensed_mask = condensed_mask[..., tf.newaxis]\n",
    "#     return condensed_mask[0]\n",
    "\n",
    "# def show_predictions(model, dataset=None, num=1):\n",
    "#     for image, mask in dataset.take(num):\n",
    "#         pred_mask = model.predict(image)\n",
    "#         display([image[0], create_mask(mask), create_mask(pred_mask)])\n",
    "\n",
    "# show_predictions(model, test, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ee8307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T19:04:35.417620Z",
     "iopub.status.busy": "2022-07-24T19:04:35.417272Z",
     "iopub.status.idle": "2022-07-24T19:04:35.426608Z",
     "shell.execute_reply": "2022-07-24T19:04:35.425711Z"
    },
    "papermill": {
     "duration": 1.817136,
     "end_time": "2022-07-24T19:04:35.428681",
     "exception": false,
     "start_time": "2022-07-24T19:04:33.611545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img_name = 'N-33-60-D-c-4-2'\n",
    "# IMAGE_PATH = '../input/landcoverai/images/{}.tif'.format(img_name)\n",
    "# LABEL_PATH = '../input/landcoverai/masks/{}.tif'.format(img_name)\n",
    "\n",
    "# def from_one_hot_to_rgb_bkup(class_indexes, palette=None):\n",
    "#     \"\"\" \n",
    "#     https://stackoverflow.com/a/60811084/6328456\n",
    "#     Assign a different color to each class in the input tensor \n",
    "#     \"\"\"\n",
    "#     # 0 is background, 1 is building, 2 is woodland, 3 is water, 4 is road\n",
    "#     if palette is None:\n",
    "#         palette = tf.constant(\n",
    "#             [[0, 0, 0], #background - black\n",
    "#             [128, 87, 43], #building - brown\n",
    "#             [12, 243, 12], #woodland - light green\n",
    "#             [12, 122, 251], #water - sky blue\n",
    "#             [79, 12, 75]] #road - dark purple\n",
    "#         , dtype=tf.int32)\n",
    "\n",
    "#     H, W, _ = class_indexes.shape\n",
    "#     class_indexes = tf.cast(class_indexes, tf.int32)\n",
    "\n",
    "#     color_image = tf.gather(palette, class_indexes)\n",
    "#     color_image = tf.reshape(color_image, [H, W, 3])\n",
    "\n",
    "#     color_image = tf.cast(color_image, dtype=tf.float32)\n",
    "#     return color_image\n",
    "\n",
    "# def pad_image_to_tile_multiple(image3, tile_size, padding=\"CONSTANT\"):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Pad an image to a multiple of the tile size.\n",
    "#     Input:\n",
    "#         image3: A 3D tensor with shape (H,W,C)\n",
    "#         tile_size: Tuple denoting size of the tiles.\n",
    "#         padding: Padding type for tf.pad command.\n",
    "#     Returns:\n",
    "#         A padded tensor.\n",
    "#     '''\n",
    "#     original_image_size = image3.shape\n",
    "#     image_size = tf.shape(image3)[0:2]\n",
    "#     padding_ = tf.cast(tf.math.ceil(image_size / tile_size), tf.int32) * tile_size - image_size\n",
    "#     return original_image_size, tf.pad(image3, [[0, padding_[0]], [0, padding_[1]], [0, 0]], padding)\n",
    "\n",
    "# def remove_image_padding(image3, original_img_shape):\n",
    "#     image3 = image3[0:original_img_shape[0], 0:original_img_shape[1], :]\n",
    "#     return image3\n",
    "\n",
    "# def split_image(image3, tile_size):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Split an image into tiles. Converts a 3D tensor with shape (H,W,C) to a 4D tensor with shape (B,H,W,C).\n",
    "#     Input:\n",
    "#         image3: A 3D tensor with shape (H,W,C)\n",
    "#         tile_size: Tuple denoting size of the tiles.\n",
    "#     Returns:\n",
    "#         A 4D tensor with shape (B,H,W,C)\n",
    "#     '''\n",
    "#     image_shape = tf.shape(image3)\n",
    "#     tile_rows = tf.reshape(image3, [image_shape[0], -1, tile_size[1], image_shape[2]])\n",
    "#     serial_tiles = tf.transpose(tile_rows, [1, 0, 2, 3])\n",
    "#     return tf.reshape(serial_tiles, [-1, tile_size[1], tile_size[0], image_shape[2]])\n",
    "\n",
    "# def unsplit_image(tiles4, image_shape):\n",
    "#     '''\n",
    "#     https://stackoverflow.com/a/46181172/6328456\n",
    "#     Unsplit a tiles into an image. Converts a 4D tensor with [B,H,W,C] to a 3D tensor with [H,W,C].\n",
    "#     Input:\n",
    "#         tiles4: A 4D tensor with shape (B,H,W,C)\n",
    "#         image_shape: Tuple denoting size of the image.\n",
    "#     Returns:\n",
    "#         A 3D tensor with shape (H,W,C)\n",
    "#     '''\n",
    "#     tile_width = tf.shape(tiles4)[1]\n",
    "#     serialized_tiles = tf.reshape(tiles4, [-1, image_shape[0], tile_width, image_shape[2]])\n",
    "#     rowwise_tiles = tf.transpose(serialized_tiles, [1, 0, 2, 3])\n",
    "#     return tf.reshape(rowwise_tiles, [image_shape[0], image_shape[1], image_shape[2]])\n",
    "\n",
    "# # Read image and convert to tensor\n",
    "# img = cv2.imread(IMAGE_PATH)\n",
    "# label = cv2.imread(LABEL_PATH, cv2.IMREAD_UNCHANGED)\n",
    "# img = tf.convert_to_tensor(img, tf.float32)\n",
    "# img = img / 255.0\n",
    "# label = tf.convert_to_tensor(label, tf.float32)\n",
    "# label = label[..., tf.newaxis]\n",
    "\n",
    "# # Pad the image and label\n",
    "# original_label_shape, _ = pad_image_to_tile_multiple(label, [256, 256])\n",
    "# padded_label_shape = _.shape\n",
    "# original_img_shape, img = pad_image_to_tile_multiple(img, [256, 256])\n",
    "\n",
    "# # Split the padded image into batches and pad the batches\n",
    "# tiles = split_image(img, [256, 256])\n",
    "\n",
    "# pred_masks = model.predict(tiles)\n",
    "# pred_masks = tf.math.argmax(pred_masks, axis=-1)\n",
    "# pred_masks = pred_masks[...,tf.newaxis]\n",
    "# pred_mask = unsplit_image(pred_masks, padded_label_shape)\n",
    "\n",
    "# # Remove the padding from the image and mask\n",
    "# img = remove_image_padding(img, original_img_shape)\n",
    "# pred_mask = remove_image_padding(pred_mask, original_label_shape)\n",
    "\n",
    "# # Convert the masks to a uint8 image\n",
    "# label = from_one_hot_to_rgb_bkup(label)\n",
    "# pred_mask = from_one_hot_to_rgb_bkup(pred_mask)\n",
    "# label = tf.keras.utils.array_to_img(label)\n",
    "# pred_mask = tf.keras.utils.array_to_img(pred_mask)\n",
    "\n",
    "# # Save as png\n",
    "# # img = tf.io.encode_png(tf.cast(img, tf.uint8))\n",
    "# # tf.io.write_file('{}_0.png'.format(img_name), img)\n",
    "# label.save('{}_label.png'.format(img_name))\n",
    "# pred_mask.save('{}_predMask.png'.format(img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbb5e9",
   "metadata": {
    "papermill": {
     "duration": 1.787989,
     "end_time": "2022-07-24T19:04:39.124801",
     "exception": false,
     "start_time": "2022-07-24T19:04:37.336812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24305.198017,
   "end_time": "2022-07-24T19:04:44.830775",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-24T12:19:39.632758",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
